{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1540,"status":"ok","timestamp":1768183822891,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"401Gn_ARXRbC","outputId":"d43a3a3c-408d-4190-8ead-a11c73dae891"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4941,"status":"ok","timestamp":1768183827824,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"hNsfcy9qXdYX"},"outputs":[],"source":["import sys\n","from pathlib import Path\n","import torch\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","import h5py\n","import pandas as pd\n","# Define the project path\n","PROJECT_PATH = Path('/content/drive/MyDrive/AutomaticHeartSoundClassification-main')\n","sys.path.append(str(PROJECT_PATH))\n","\n","DATASET_PATH = Path('/content/drive/MyDrive/AutomaticHeartSoundClassification-main/data')\n","sys.path.append(str(DATASET_PATH))\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","DATARAW_PATH = Path('/content/drive/MyDrive/physionet2016')\n","sys.path.append(str(DATASET_PATH))"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1768183827828,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"GjH6meUPWP7Q"},"outputs":[],"source":["MODEL_NAME = \"CRNN\"      # hoặc \"CNN\"\n","TIMESTAMP = \"0108_105831\""]},{"cell_type":"markdown","source":["# Dowload Package"],"metadata":{"id":"qhPA-yGw9fkz"}},{"cell_type":"code","source":["import importlib\n","import subprocess\n","import sys\n","\n","def check_or_install(pkg_name, import_name=None, version=None):\n","    \"\"\"\n","    Check whether a Python package is already installed.\n","    If the package exists, print its current version.\n","    If the package does not exist, install the specified version.\n","\n","    Parameters\n","    ----------\n","    pkg_name : str\n","        Package name as registered on PyPI.\n","    import_name : str, optional\n","        Module name used for import (if different from pkg_name).\n","    version : str, optional\n","        Required version. If None, any installed version is accepted.\n","    \"\"\"\n","    name = import_name if import_name else pkg_name\n","\n","    try:\n","        # Try to import the package\n","        module = importlib.import_module(name)\n","\n","        # Retrieve the package version if available\n","        ver = getattr(module, \"__version__\", \"unknown\")\n","\n","        print(f\"[OK] {pkg_name} is already installed (version: {ver})\")\n","\n","    except ImportError:\n","        # Construct the pip install command\n","        install_target = pkg_name if version is None else f\"{pkg_name}=={version}\"\n","\n","        print(f\"[INSTALL] {pkg_name} not found. Installing {install_target} ...\")\n","\n","        # Install the package using pip\n","        subprocess.check_call([\n","            sys.executable,\n","            \"-m\",\n","            \"pip\",\n","            \"install\",\n","            install_target\n","        ])"],"metadata":{"id":"XxdBv_bP_RiI","executionInfo":{"status":"ok","timestamp":1768183827875,"user_tz":-420,"elapsed":19,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#!pip install numpy==1.26.4"],"metadata":{"id":"H_Sl_y7m9Ram","executionInfo":{"status":"ok","timestamp":1768183827890,"user_tz":-420,"elapsed":13,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Core ONNX ecosystem (recommended stable versions)\n","check_or_install(\"onnx\", version=\"1.17.0\")\n","check_or_install(\"onnxsim\", import_name=\"onnxsim\", version=\"0.4.33\")\n","check_or_install(\"onnx-graphsurgeon\", import_name=\"onnx_graphsurgeon\")\n","\n","# Runtime and model conversion tools\n","check_or_install(\"onnxruntime\", import_name=\"onnxruntime\", version=\"1.18.1\")\n","check_or_install(\"onnx2tf\", import_name=\"onnx2tf\")\n","check_or_install(\"onnxscript \", import_name=\"onnxscript\")\n","check_or_install(\"numpy\", version=\"1.26.4\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tq2MVsyR_Pva","executionInfo":{"status":"ok","timestamp":1768183833452,"user_tz":-420,"elapsed":5550,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"1c469342-b58b-43d0-cfec-d01528a45d8e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[OK] onnx is already installed (version: 1.17.0)\n","[OK] onnxsim is already installed (version: 0.4.33)\n","[OK] onnx-graphsurgeon is already installed (version: 0.5.8)\n","[OK] onnxruntime is already installed (version: 1.18.1)\n","[OK] onnx2tf is already installed (version: 1.28.8)\n","[OK] onnxscript  is already installed (version: 0.5.7)\n","[OK] numpy is already installed (version: 1.26.4)\n"]}]},{"cell_type":"code","source":["# TensorFlow and Keras (stable and compatible versions)\n","check_or_install(\"tensorflow\", import_name=\"tensorflow\", version=\"2.19.0\")\n","check_or_install(\"tf-keras\", import_name=\"tf_keras\", version=\"2.19.0\")\n","\n","# Auxiliary packages for signal processing and edge deployment\n","check_or_install(\"h5py\")\n","check_or_install(\"librosa\")\n","check_or_install(\"ai_edge_litert\", version=\"1.2.0\")\n","check_or_install(\"sng4onnx\")"],"metadata":{"id":"4aX8jXFaCe_4","executionInfo":{"status":"ok","timestamp":1768183833517,"user_tz":-420,"elapsed":62,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"26c97f1b-e6c1-4dbd-f69d-5be33979fba8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[OK] tensorflow is already installed (version: 2.19.0)\n","[OK] tf-keras is already installed (version: 2.19.0)\n","[OK] h5py is already installed (version: 3.15.1)\n","[OK] librosa is already installed (version: 0.11.0)\n","[OK] ai_edge_litert is already installed (version: 1.2.0)\n","[OK] sng4onnx is already installed (version: 1.0.4)\n"]}]},{"cell_type":"code","source":["import onnx\n","print(\"ONNX version:\", onnx.__version__)\n","print(\"ONNX file:\", onnx.__file__)"],"metadata":{"id":"MjD0OjVIvw99","executionInfo":{"status":"ok","timestamp":1768183833538,"user_tz":-420,"elapsed":19,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6be2ba94-6816-4b30-f8c1-e23ecbbbb516"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["ONNX version: 1.17.0\n","ONNX file: /usr/local/lib/python3.12/dist-packages/onnx/__init__.py\n"]}]},{"cell_type":"markdown","metadata":{"id":"VXY88r3qvOIh"},"source":["# Loss and Metrics"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1768183833579,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"-FeevTs-vNRt"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","\n","def nll_loss(output, target):\n","    return F.nll_loss(output, target)\n","\n","def ce_loss(output, target):\n","    return F.cross_entropy(output, target)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1768183833591,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"7G1FN5QfvTA0"},"outputs":[],"source":["import torch\n","\n","\n","def accuracy(output, target):\n","    with torch.no_grad():\n","        pred = torch.argmax(output, dim=1)\n","        assert pred.shape[0] == len(target)\n","        correct = 0\n","        correct += torch.sum(pred == target).item()\n","    return correct / len(target)\n","\n","\n","def top_k_acc(output, target, k=3):\n","    with torch.no_grad():\n","        pred = torch.topk(output, k, dim=1)[1]\n","        assert pred.shape[0] == len(target)\n","        correct = 0\n","        for i in range(k):\n","            correct += torch.sum(pred[:, i] == target).item()\n","    return correct / len(target)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1768183833602,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"jh-2LBAArwXk"},"outputs":[],"source":["MODEL_DIR_MAP = {\n","    \"VGG11\": \"VGG11\",\n","    \"CNN\": \"simple_cnn\",\n","    \"CRNN\": \"CRNN\",\n","    \"LSTM\": \"LSTM\",\n","}\n"]},{"cell_type":"markdown","metadata":{"id":"-9PUjPYfB6yh"},"source":["# Config Parse"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1768183833603,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"TrxXISKCB8wq"},"outputs":[],"source":["import os\n","import logging\n","from pathlib import Path\n","from datetime import datetime\n","import argparse\n","import collections\n","import importlib.util\n","\n","class ConfigParser:\n","    def __init__(self, config_dict, resume=None, modification=None, run_id=None):\n","        self._config = config_dict\n","        self.resume = resume\n","\n","        # Apply CLI modifications\n","        if modification:\n","            for key_path, value in modification.items():\n","                keys = key_path.split(';')\n","                d = self._config\n","                for k in keys[:-1]:\n","                    d = d[k]\n","                d[keys[-1]] = value\n","\n","        # Setup save and log directories\n","        save_dir = Path(self.config['trainer']['save_dir'])\n","        exper_name = self.config['name']\n","        if run_id is None:\n","            run_id = datetime.now().strftime(r'%m%d_%H%M%S')\n","        self._save_dir = save_dir / 'models' / exper_name / run_id\n","        self._log_dir = save_dir / 'log' / exper_name / run_id\n","\n","        self.save_dir.mkdir(parents=True, exist_ok=True)\n","        self.log_dir.mkdir(parents=True, exist_ok=True)\n","\n","        # Optional: setup logging\n","        # setup_logging(self.log_dir)\n","\n","    @classmethod\n","    def from_args(cls, parser, options=None):\n","        \"\"\"\n","        parser: argparse.ArgumentParser đã được add_argument xong\n","        options: list các CustomArgs để override\n","        \"\"\"\n","        if options is None:\n","            options = []\n","\n","        # Parse arguments (an toàn cho cả terminal và notebook)\n","        args = parser.parse_args()\n","\n","        # Xử lý device\n","        if args.device is not None:\n","            os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.device\n","\n","        # Xử lý resume\n","        if args.resume is not None:\n","            resume = Path(args.resume)\n","            cfg_fname = resume.parent / 'config.py'  # hoặc .json nếu bạn dùng cả 2\n","        else:\n","            resume = None\n","            assert args.config is not None, \"Phải chỉ định -c config.py\"\n","            cfg_fname = Path(args.config)\n","\n","        # Đọc config từ file .py\n","        if not cfg_fname.exists():\n","            raise FileNotFoundError(f\"Không tìm thấy config file: {cfg_fname}\")\n","\n","        if cfg_fname.suffix == '.py':\n","            spec = importlib.util.spec_from_file_location(\"config_module\", cfg_fname)\n","            config_module = importlib.util.module_from_spec(spec)\n","            spec.loader.exec_module(config_module)\n","            if not hasattr(config_module, 'config'):\n","                raise ValueError(f\"File {cfg_fname} phải định nghĩa biến 'config'\")\n","            config_dict = config_module.config\n","        else:\n","            raise ValueError(\"Chỉ hỗ trợ file config .py\")\n","\n","        # Parse custom CLI overrides\n","        CustomArgs = collections.namedtuple('CustomArgs', 'flags type target')\n","        modification = {}\n","        for opt in options:\n","            for flag in opt.flags:\n","                arg_name = flag.lstrip('-').replace('-', '_')\n","                if hasattr(args, arg_name) and getattr(args, arg_name) is not None:\n","                    modification[opt.target] = opt.type(getattr(args, arg_name))\n","\n","        return cls(config_dict, resume, modification)\n","\n","    def init_obj(self, name, module, *args, **kwargs):\n","        module_name = self[name]['type']\n","        module_args = dict(self[name]['args'])\n","        module_args.update(kwargs)\n","        if isinstance(module, dict):\n","            obj_class = module[module_name]\n","        else:\n","            obj_class = getattr(module, module_name)\n","\n","        return obj_class(*args, **module_args)\n","\n","    def init_ftn(self, name, module, *args, **kwargs):\n","        from functools import partial\n","        module_name = self[name]['type']\n","        module_args = dict(self[name]['args'])\n","        module_args.update(kwargs)\n","        if isinstance(module, dict):\n","            obj_class = module[module_name]\n","        else:\n","            obj_class = getattr(module, module_name)\n","\n","        return obj_class(*args, **module_args)\n","\n","    def __getitem__(self, name):\n","        return self.config[name]\n","\n","    def get_logger(self, name, verbosity=2):\n","        logger = logging.getLogger(name)\n","        logger.setLevel({0: logging.WARNING, 1: logging.INFO, 2: logging.DEBUG}[verbosity])\n","        return logger\n","\n","    @property\n","    def config(self):\n","        return self._config\n","\n","    @property\n","    def save_dir(self):\n","        return self._save_dir\n","\n","    @property\n","    def log_dir(self):\n","        return self._log_dir"]},{"cell_type":"markdown","metadata":{"id":"WhoAQsZG0w_a"},"source":["# Model"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1768183833605,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"SAl1_zBs622s"},"outputs":[],"source":["import torch.nn as nn\n","import numpy as np\n","from abc import abstractmethod\n","\n","\n","class BaseModel(nn.Module):\n","    \"\"\"\n","    Base class for all models\n","    \"\"\"\n","    @abstractmethod\n","    def forward(self, *inputs):\n","        \"\"\"\n","        Forward pass logic\n","\n","        :return: Model output\n","        \"\"\"\n","        raise NotImplementedError\n","\n","    def __str__(self):\n","        \"\"\"\n","        Model prints with number of trainable parameters\n","        \"\"\"\n","        model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n","        params = sum([np.prod(p.size()) for p in model_parameters])\n","        return super().__str__() + '\\nTrainable parameters: {}'.format(params)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1768183833613,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"acHCNOa2649Y"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","# functions of initializing layers\n","def init_layer(layer):\n","    \"\"\"Initialize a Linear or Convolutional layer.\"\"\"\n","    nn.init.xavier_uniform_(layer.weight)\n","\n","    if hasattr(layer, 'bias'):\n","        if layer.bias is not None:\n","            layer.bias.data.fill_(0.)\n","\n","def init_bn(bn):\n","    \"\"\"Initialize a Batchnorm layer.\"\"\"\n","    bn.bias.data.fill_(0.)\n","    bn.weight.data.fill_(1.)\n","\n","def init_rnn(rnn):\n","    \"\"\"init_rnn\n","    Initialized RNN weights, independent of type GRU/LSTM/RNN\n","    :param rnn: the rnn model\n","    \"\"\"\n","    for name, param in rnn.named_parameters():\n","        if 'bias' in name:\n","            nn.init.constant_(param, 0.0)\n","        elif 'weight' in name:\n","            nn.init.xavier_uniform_(param)\n","\n","def reset_parameters(model):\n","    for module in model.modules():\n","        if isinstance(module, nn.Conv2d):\n","            init_layer(module)\n","        elif isinstance(module, nn.Linear):\n","            init_layer(module)\n","        elif isinstance(module, nn.BatchNorm2d):\n","            init_bn(module)\n","        elif isinstance(module, nn.LSTM):\n","            init_rnn(module)\n"]},{"cell_type":"markdown","metadata":{"id":"EwJI6ZEB0zNA"},"source":["## CNN"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1768183833648,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"wFz-dHoL07Oz"},"outputs":[],"source":["class simple_cnn(BaseModel):\n","    def __init__(self, num_classes = 2, in_channel=1):\n","        super(simple_cnn, self).__init__()\n","        self.in_channel = in_channel\n","        self.conv1 = nn.Conv2d(in_channel,16,3)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16,32,3)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32,64,3)\n","        self.bn3 = nn.BatchNorm2d(64)\n","        self.pool = nn.AdaptiveMaxPool2d(1)\n","        self.fc1 = nn.Linear(64,32)\n","        self.output = nn.Linear(32,num_classes)\n","        self.activate = nn.Softmax(dim=1)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_layer(self.conv1)\n","        init_layer(self.conv2)\n","        init_layer(self.conv3)\n","        init_layer(self.fc1)\n","        init_layer(self.output)\n","        init_bn(self.bn1)\n","        init_bn(self.bn2)\n","        init_bn(self.bn3)\n","\n","\n","    def forward(self,x):\n","        B, mel_bins, num_frames = x.size()\n","        x = x.view(B, self.in_channel, -1, num_frames)\n","        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n","        x = self.bn1(x)\n","        x = F.max_pool2d(F.relu(self.conv2(x)),(2,2))\n","        x = self.bn2(x)\n","        x = F.max_pool2d(F.relu(self.conv3(x)),(2,2))\n","        x = self.bn3(x)\n","        x = self.pool(x).reshape(x.size(0),-1)\n","        x = self.fc1(x)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        out = self.output(x)\n","        out = self.activate(out)\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"8__umSV11B4M"},"source":["## Deeper CNN model, VGG like structure"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1768183833653,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"jNkSYUYJ1Hst"},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ConvBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_channels = in_channels,\n","                               out_channels = out_channels,\n","                               kernel_size = (3,3),\n","                               stride = (1,1),\n","                               padding = (1,1),\n","                               bias =False)\n","\n","        self.conv2 = nn.Conv2d(in_channels = out_channels,\n","                               out_channels = out_channels,\n","                               kernel_size = (3,3),\n","                               stride = (1,1),\n","                               padding = (1,1),\n","                               bias = False)\n","\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_layer(self.conv1)\n","        init_layer(self.conv2)\n","        init_bn(self.bn1)\n","        init_bn(self.bn2)\n","\n","    def forward(self, input, pool_size=(2, 2), pool_type='max', activation = 'relu'):\n","        x = input\n","        x = F.relu_(self.bn1(self.conv1(x)))\n","        if activation == 'relu':\n","            x = F.relu_(self.bn2(self.conv2(x)))\n","        elif activation == 'sigmoid':\n","            x = torch.sigmoid(self.bn2(self.conv2(x)))\n","\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","\n","        return x\n","\n","class VGG_11(BaseModel):\n","    def __init__(self, num_classes, in_channel):\n","        super(VGG_11, self).__init__()\n","        self.in_channel = in_channel\n","        self.bn0 = nn.BatchNorm2d(128)\n","        self.conv1 = ConvBlock(in_channels=in_channel, out_channels=64)\n","        self.conv2 = ConvBlock(in_channels=64, out_channels=128)\n","        self.conv3 = ConvBlock(in_channels=128, out_channels=256)\n","        self.conv4 = ConvBlock(in_channels=256, out_channels=512)\n","        self.fc_final = nn.Linear(512, num_classes)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_bn(self.bn0)\n","        init_layer(self.fc_final)\n","\n","    def forward(self, input):\n","        # (batch_size, 3, mel_bins, time_stamps)\n","        B, mel_bins, num_frames = input.size()\n","        x = input.view(B, self.in_channel, -1, num_frames)\n","        x = x.transpose(1, 2)\n","        x = self.bn0(x)\n","        x = x.transpose(1,2)\n","\n","        # (samples_num, channel, mel_bins, time_stamps)\n","        x = self.conv1(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv2(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv3(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training = self.training)\n","        x = self.conv4(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","\n","        output = F.max_pool2d(x, kernel_size=x.shape[2:])\n","        output = output.view(output.shape[0:2])\n","        output = F.log_softmax(self.fc_final(output), dim=-1)\n","        return output\n","\n","\n","class VGG_13(BaseModel):\n","    def __init__(self, num_classes, in_channel):\n","        super(VGG_13, self).__init__()\n","        self.in_channel = in_channel\n","        self.bn0 = nn.BatchNorm2d(128)\n","        self.conv1 = ConvBlock(in_channels=in_channel, out_channels=64)\n","        self.conv2 = ConvBlock(in_channels=64, out_channels=128)\n","        self.conv3 = ConvBlock(in_channels=128, out_channels=256)\n","        self.conv4 = ConvBlock(in_channels=256, out_channels=512)\n","        self.conv5 = ConvBlock(in_channels=512, out_channels=512)\n","        self.fc_1 = nn.Linear(512 * 4* 10, 4096)\n","        self.fc_2 = nn.Linear(4096, 4096)\n","        self.fc_final = nn.Linear(4096, num_classes)\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_bn(self.bn0)\n","        init_layer(self.fc_final)\n","        init_layer(self.fc_1)\n","        init_layer(self.fc_2)\n","\n","    def forward(self, input):\n","        # (batch_size, 3, mel_bins, time_stamps)\n","        B, mel_bins, num_frames = input.size()\n","        x = input.view(B, self.in_channel, -1, num_frames)\n","        x = x.transpose(1, 2)\n","        x = self.bn0(x)\n","        x = x.transpose(1,2)\n","\n","        # (samples_num, channel, time_stemps, mel_bins)\n","        x = self.conv1(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv2(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv3(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training = self.training)\n","        x = self.conv4(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv5(x, pool_size=(2, 2), pool_type='max')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        #output = F.max_pool2d(x, kernel_size=x.shape[2:])\n","        #output = output.view(output.shape[0:2])\n","        x = x.view(x.shape[0], -1)\n","        x = F.relu_(self.fc_1(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu_(self.fc_2(x))\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        output = F.log_softmax(self.fc_final(x),dim=-1)\n","        #output = F.log_softmax(self.fc_final(output), dim=-1)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"_tiWnXK_1KNt"},"source":["## RNN - BiLTSM"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1768183833658,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"GyEol78F1K8k"},"outputs":[],"source":["class BiLSTM(BaseModel):\n","    def __init__(self,\n","                 input_dim=200,\n","                 hidden_dim=256,\n","                 num_layers =2,\n","                 dropout=0.2,\n","                 num_classes=2,\n","                 pooling='first',\n","                 model='lstm',\n","                 BN=False):\n","        super(BiLSTM,self).__init__()\n","        if model == 'lstm':\n","            self.LSTM = nn.LSTM(input_size=input_dim,\n","                                hidden_size =hidden_dim,\n","                                num_layers =num_layers,\n","                                batch_first =True,\n","                                dropout=dropout,\n","                                bidirectional=True)\n","        elif model == 'gru':\n","            self.LSTM = nn.GRU(input_size=input_dim,\n","                               hidden_size =hidden_dim,\n","                               num_layers =num_layers,\n","                               batch_first =True,\n","                               dropout=dropout,\n","                               bidirectional=True)\n","        init_rnn(self.LSTM)\n","        self.BN = BN\n","        if self.BN:\n","            self.BatchNorm=nn.BatchNorm1d(hidden_dim*2)\n","\n","        self.layer_out = nn.Linear(hidden_dim*2,num_classes,bias=False)\n","        self.pooling=pooling\n","\n","    def forward(self,x):\n","        x = x.transpose(2,1) #[Batchsize x Time_frames x Mel_bin]\n","        x,_ = self.LSTM(x)\n","        if self.BN:\n","            x = self.BatchNorm(x.transpose(1,2))\n","            x = x.transpose(1,2)\n","        dim =1\n","        x = self.layer_out(x)  #200,2\n","        if self.pooling == 'avg':\n","            x = x.mean(dim)   #average pooling\n","        elif self.pooling == 'first':\n","            x = x.select(dim,0)  #first time step\n","        elif self.pooling == 'last':\n","            x = x.select(dim,-1)  #first time step\n","        elif self.pooling == 'max':\n","            x = x.max(dim)[0]\n","        elif  self.pooling == 'linear':\n","            (x**2).sum(dim) / x.sum(dim)\n","        elif self.pooling == 'exp':\n","            (x.exp() * x).sum(dim) / x.exp().sum(dim)\n","\n","        # print(out.shape)\n","        # out = self.LogSoftmax(out)#the input given is expected to contain log-probabilities. Obtaining log-probabilities in a neural network is easily achieved by adding a LogSoftmax layer in the last layer of your network.\n","        return x#,A"]},{"cell_type":"markdown","metadata":{"id":"6T_AW7vl1N4R"},"source":["## CRNN"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1768183833680,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"yPAtlVzM1PzB"},"outputs":[],"source":["class CNN_Encoder(nn.Module):\n","    def __init__(self, in_channels):\n","        super(CNN_Encoder, self).__init__()\n","\n","        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=32)\n","        self.conv2 = ConvBlock(in_channels=32, out_channels=64)\n","        self.conv3 = ConvBlock(in_channels=64, out_channels=128)\n","        self.conv4 = ConvBlock(in_channels=128, out_channels=256)\n","    def forward(self, input):\n","        x = input\n","        x = self.conv1(x, pool_size=(2, 2))\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv2(x, pool_size=(2, 2))\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv3(x, pool_size=(2, 2))\n","        x = F.dropout(x, p=0.2, training = self.training)\n","        x = self.conv4(x, pool_size=(2, 2))\n","        x = F.dropout(x, p=0.2, training=self.training)\n","\n","        return x\n","\n","class crnn(BaseModel):\n","    def __init__(self, in_channel,\n","                 hidden_dim=128,\n","                 num_layers = 2,\n","                 dropout = 0.2,\n","                 pooling = 'first',\n","                 model='lstm',\n","                 BN = False,\n","                 num_classes=2):\n","        super(crnn,self).__init__()\n","\n","        self.in_channel = in_channel\n","        #self.bn0 = nn.BatchNorm2d(128)\n","        self.bn0 = None\n","\n","        self.cnn = CNN_Encoder(in_channels=in_channel)\n","        self.bilstm = BiLSTM(input_dim=256,\n","                             hidden_dim=hidden_dim,\n","                             num_layers =num_layers,\n","                             dropout =dropout,\n","                             num_classes=num_classes,\n","                             pooling=pooling,\n","                             model=model,\n","                             BN=BN)\n","\n","\n","    def forward(self,input):\n","        # (batch_size, 3, mel_bins, time_stamps)\n","        B, mel_bins, num_frames = input.size()\n","        #x = input.view(B, self.in_channel, -1, num_frames)\n","        #x = x.transpose(1, 2)\n","        x = input.view(B, self.in_channel, mel_bins // self.in_channel, num_frames)\n","\n","        x = self.cnn(x)\n","        #x = F.max_pool2d(x,kernel_size=(x.size(-2), 1)) # pool mel dimension\n","        x = F.adaptive_max_pool2d(x, (1, None))\n","        x = x.squeeze(-2)  # [B x C x Time_frames]\n","\n","        output = self.bilstm(x)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"JntaM1sMtRnP"},"source":["# Load Model"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1768183833686,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"UBVDUv-HXfGW"},"outputs":[],"source":["from pathlib import Path\n","\n","def get_model_best_path(project_path, model_name, timestamp):\n","    \"\"\"\n","    Trả về đường dẫn tới model_best.pth theo cấu trúc chuẩn:\n","    saved/<model_dir>/models/Physionet_<model_dir>/<timestamp>/model_best.pth\n","    \"\"\"\n","\n","    if model_name not in MODEL_DIR_MAP:\n","        raise ValueError(f\"Unsupported model name: {model_name}\")\n","\n","    model_dir = MODEL_DIR_MAP[model_name]\n","\n","    return (\n","        project_path\n","        / \"saved\"\n","        / model_dir\n","        / \"models\"\n","        / f\"Physionet_{model_dir}\"\n","        / timestamp\n","        / \"model_best.pth\"\n","    )\n"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1768183833719,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"B7TQTt-kXhte","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d2fec23-94bd-4c53-c9e6-4981c2bb9254"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AutomaticHeartSoundClassification-main/saved/CRNN/models/Physionet_CRNN/0108_105831/model_best.pth\n"]}],"source":["model_path = get_model_best_path(\n","    project_path=PROJECT_PATH,\n","    model_name=MODEL_NAME,\n","    timestamp=TIMESTAMP\n",")\n","\n","print(model_path)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1768183833770,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"E3Hp9lsekLlY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1fe0d4ab-919a-4a0e-c3bf-a389ddbae6b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ File exists!\n","   Size: 58.37 MB (61,207,937 bytes)\n"]}],"source":["if model_path.exists():\n","    size_bytes = model_path.stat().st_size\n","\n","    # Convert to human-readable format\n","    if size_bytes < 1024:\n","        size_str = f\"{size_bytes} Bytes\"\n","    elif size_bytes < 1024**2:\n","        size_str = f\"{size_bytes / 1024:.2f} KB\"\n","    elif size_bytes < 1024**3:\n","        size_str = f\"{size_bytes / (1024**2):.2f} MB\"\n","    else:\n","        size_str = f\"{size_bytes / (1024**3):.2f} GB\"\n","\n","    print(f\"✅ File exists!\")\n","    print(f\"   Size: {size_str} ({size_bytes:,} bytes)\")\n","else:\n","    print(\"❌ File does NOT exist at the specified path.\")\n","    print(\"   Possible reasons:\")\n","    print(\"   - Training did not complete or model_best.pth was not saved\")\n","    print(\"   - Wrong timestamp (check your actual training time)\")\n","    print(\"   - Model saved elsewhere (e.g., in TFLITE folder)\")\n","    print()\n","    print(\"Searching for all .pth files in the project for suggestions...\")\n","\n","    # Search for any .pth files in the entire project\n","    pth_files = sorted(PROJECT_PATH.rglob(\"*.pth\"))\n","    if pth_files:\n","        print(\"\\nFound .pth files:\")\n","        for p in pth_files[:10]:  # Show max 10 files\n","            rel_size = p.stat().st_size / (1024**2)\n","            print(f\"   → {p.relative_to(PROJECT_PATH)}  ({rel_size:.2f} MB)\")\n","        if len(pth_files) > 10:\n","            print(f\"   ... and {len(pth_files)-10} more files\")\n","    else:\n","        print(\"   No .pth files found in the entire project!\")"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1768183833770,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"EfDkjYYu88Re"},"outputs":[],"source":["MODEL_CLASS_MAP = {\n","    \"VGG11\": {\n","        \"class\": VGG_11,\n","        \"in_channel\": 3,\n","        \"num_classes\": 2\n","    },\n","    \"CNN\": {\n","        \"class\": simple_cnn,\n","        \"in_channel\": 3,\n","        \"num_classes\": 2\n","    },\n","    \"CRNN\": {\n","        \"class\": crnn,\n","        \"in_channel\": 1,\n","        \"num_classes\": 2,\n","        # Các tham số mặc định cho CRNN (có thể chỉnh nếu cần)\n","        \"extra_kwargs\": {\n","            \"hidden_dim\": 256,\n","            \"num_layers\": 2,\n","            \"dropout\": 0.2,\n","            \"pooling\": \"first\",\n","            \"model\": \"lstm\",\n","            \"BN\": False\n","        }\n","    },\n","    \"LSTM\": {\n","        \"class\": BiLSTM,\n","        \"in_channel\": None,  # Không dùng in_channel\n","        \"num_classes\": 2,\n","        \"extra_kwargs\": {\n","            \"input_dim\": 128,      # Thường là số mel bins sau khi pool mel dim\n","            \"hidden_dim\": 256,\n","            \"num_layers\": 2,\n","            \"dropout\": 0.2,\n","            \"pooling\": \"first\",\n","            \"model\": \"lstm\",\n","            \"BN\": False\n","        }\n","    }\n","}"]},{"cell_type":"code","source":["def build_model_for_convert(model_name: str, cfg: dict):\n","    ModelClass = cfg[\"class\"]\n","    model_cfg = cfg[\"model\"]\n","    input_cfg = cfg[\"input\"]\n","\n","    # ===== CRNN =====\n","    if model_name == \"CRNN\":\n","        model = ModelClass(\n","            in_channel=input_cfg[\"in_channel\"],\n","            hidden_dim=model_cfg[\"hidden_dim\"],\n","            num_layers=model_cfg[\"num_layers\"],\n","            dropout=model_cfg[\"dropout\"],\n","            pooling=model_cfg[\"pooling\"],\n","            model=model_cfg[\"rnn_type\"],\n","            BN=model_cfg[\"BN\"],\n","            num_classes=model_cfg[\"num_classes\"]\n","        )\n","\n","    # ===== LSTM =====\n","    elif model_name == \"LSTM\":\n","        model = ModelClass(\n","            input_dim=input_cfg[\"mel_bins\"],\n","            hidden_dim=model_cfg[\"hidden_dim\"],\n","            num_layers=model_cfg[\"num_layers\"],\n","            dropout=model_cfg[\"dropout\"],\n","            num_classes=model_cfg[\"num_classes\"]\n","        )\n","\n","    # ===== CNN / VGG =====\n","    else:\n","        model = ModelClass(\n","            in_channel=input_cfg[\"in_channel\"],\n","            num_classes=model_cfg[\"num_classes\"]\n","        )\n","\n","    model.eval()\n","    return model\n"],"metadata":{"id":"cxQQIgMHqRYi","executionInfo":{"status":"ok","timestamp":1768183833775,"user_tz":-420,"elapsed":7,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# =========================\n","# CHECK MODEL NAME\n","# =========================\n","if MODEL_NAME not in MODEL_CLASS_MAP:\n","    raise ValueError(\n","        f\"Model {MODEL_NAME} không được hỗ trợ. \"\n","        f\"Các model hỗ trợ: {list(MODEL_CLASS_MAP.keys())}\"\n","    )\n","\n","cfg = MODEL_CLASS_MAP[MODEL_NAME]\n","ModelClass = cfg[\"class\"]\n","\n","# =========================\n","# BUILD MODEL (THEO KIẾN TRÚC)\n","# =========================\n","if MODEL_NAME == \"CRNN\":\n","    model = ModelClass(\n","        in_channel=cfg[\"in_channel\"],\n","        num_classes=cfg[\"num_classes\"],\n","        **cfg.get(\"extra_kwargs\", {})\n","    )\n","\n","elif MODEL_NAME == \"LSTM\":\n","    # LSTM ở đây là BiLSTM, không dùng in_channel\n","    model = ModelClass(\n","        num_classes=cfg[\"num_classes\"],\n","        **cfg.get(\"extra_kwargs\", {})\n","    )\n","\n","elif MODEL_NAME in [\"VGG11\", \"CNN\"]:\n","    model = ModelClass(\n","        in_channel=cfg[\"in_channel\"],\n","        num_classes=cfg[\"num_classes\"]\n","    )\n","\n","else:\n","    raise ValueError(\"Cấu hình model không hợp lệ\")\n","\n","model.to(device)\n","model.eval()"],"metadata":{"id":"xGXz7CZ4q5P0","executionInfo":{"status":"ok","timestamp":1768186981110,"user_tz":-420,"elapsed":112,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"36fc4b3d-39ec-4b0c-f0ec-f9f422fa7952"},"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["crnn(\n","  (cnn): CNN_Encoder(\n","    (conv1): ConvBlock(\n","      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv2): ConvBlock(\n","      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv3): ConvBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (conv4): ConvBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (bilstm): BiLSTM(\n","    (LSTM): LSTM(256, 256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","    (layer_out): Linear(in_features=512, out_features=2, bias=False)\n","  )\n",")"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":113,"status":"ok","timestamp":1768186984248,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"3QIy6Djz9Aeu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6977df90-6342-40b5-a3d6-8fa0277947b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Đã load model CRNN thành công từ: /content/drive/MyDrive/AutomaticHeartSoundClassification-main/saved/CRNN/models/Physionet_CRNN/0108_105831/model_best.pth\n"]}],"source":["# =========================\n","# LOAD WEIGHTS (FINAL – STRICT & SAFE)\n","# =========================\n","\n","checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n","\n","# ---- extract state_dict ----\n","if isinstance(checkpoint, dict):\n","    state_dict = checkpoint.get(\"state_dict\", checkpoint.get(\"model\", checkpoint))\n","else:\n","    state_dict = checkpoint.state_dict() if hasattr(checkpoint, \"state_dict\") else checkpoint\n","\n","# ---- remove DataParallel prefix ----\n","if all(k.startswith(\"module.\") for k in state_dict.keys()):\n","    from collections import OrderedDict\n","    state_dict = OrderedDict((k[7:], v) for k, v in state_dict.items())\n","\n","# ---- remove BiLSTM BatchNorm (BN=False) ----\n","if MODEL_NAME in [\"CRNN\", \"LSTM\"]:\n","    if hasattr(model, \"bilstm\") and hasattr(model.bilstm, \"BN\") and model.bilstm.BN is False:\n","        bn_keys = [k for k in state_dict.keys() if \"BatchNorm\" in k]\n","        for k in bn_keys:\n","            del state_dict[k]\n","\n","# ---- remove CRNN input BatchNorm (bn0) ----\n","if MODEL_NAME == \"CRNN\":\n","    bn0_keys = [k for k in state_dict.keys() if k.startswith(\"bn0.\")]\n","    for k in bn0_keys:\n","        del state_dict[k]\n","\n","# ---- load strictly ----\n","model.load_state_dict(state_dict, strict=True)\n","model.to(device)\n","model.eval()\n","\n","print(f\"✅ Đã load model {MODEL_NAME} thành công từ: {model_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"MA2a4z-V5eou"},"source":["# Punning"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":153,"status":"ok","timestamp":1768186986496,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"kTLzc77p5IVi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5404a5a0-f6ae-4b96-8d3e-b05724aacbac"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Đã apply pruning (với mask)\n"]}],"source":["import torch.nn.utils.prune as prune\n","\n","parameters_to_prune = []\n","for name, module in model.named_modules():\n","    if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n","        parameters_to_prune.append((module, 'weight'))\n","        # Optional: prune bias too\n","        # if module.bias is not None:\n","        #     parameters_to_prune.append((module, 'bias'))\n","\n","prune.global_unstructured(\n","    parameters_to_prune,\n","    pruning_method=prune.L1Unstructured,\n","    amount=0.5,  # 50% weights\n",")\n","\n","print(\"✅ Đã apply pruning (với mask)\")"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1768186988796,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"8EPwVYGnELif"},"outputs":[],"source":["features_file = DATASET_PATH / \"logmel_features.h5\"\n","label_file = DATASET_PATH / \"label.csv\""]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":44,"status":"ok","timestamp":1768186989560,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"-i4lG_4VAxJn"},"outputs":[],"source":["import librosa\n","import random\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","EPS = 1e-8\n","\n","def standard_normal_variate(data):\n","    \"\"\"Z-score normalization trên toàn bộ feature\"\"\"\n","    mean = np.mean(data)\n","    std = np.std(data) + EPS\n","    return (data - mean) / std\n","\n","class LogMelDataset(Dataset):\n","    def __init__(self, features_h5_path, label_csv_path, keys=None,\n","                 delta=True, norm=True, duration=5, hop_length=15, training=True):\n","        self.features_h5 = h5py.File(features_h5_path, 'r')\n","        self.labels_df = pd.read_csv(label_csv_path)\n","\n","        if keys is None:\n","            self.keys = list(self.features_h5.keys())\n","        else:\n","            self.keys = keys\n","\n","        # Map key (filename stem) → label\n","        self.key_to_label = dict(zip(self.labels_df.iloc[:, 0].astype(str), self.labels_df.iloc[:, 1]))\n","\n","        self.delta = delta\n","        self.norm = norm\n","        self.duration = duration\n","        self.hop_length = hop_length\n","        self.training = training\n","\n","        # Độ dài cố định: 5 giây với hop 15ms → 5000 / 15 = 333.333 → lấy 333 frames\n","        self.fixed_length = int(self.duration * 1000 / self.hop_length)  # 333\n","\n","    def __len__(self):\n","        return len(self.keys)\n","\n","    def __getitem__(self, idx):\n","        key = self.keys[idx]\n","        feature = self.features_h5[key][()]  # shape: (mel_bins, time_frames), thường là (128, T)\n","\n","        # Chuẩn hóa Z-score nếu bật\n","        if self.norm:\n","            feature = standard_normal_variate(feature)\n","\n","        # Đảm bảo luôn là 3D: (C, mel_bins, T)\n","        if feature.ndim == 2:\n","            feature = feature[np.newaxis, :, :]  # (1, 128, T)\n","\n","        channels, mel_bins, num_frames = feature.shape\n","\n","        # Thêm delta + delta-delta nếu bật\n","        if self.delta:\n","            orig = feature[0]  # (128, T)\n","            delta1 = librosa.feature.delta(orig)\n","            delta2 = librosa.feature.delta(delta1)\n","            feature = np.stack([orig, delta1, delta2], axis=0)  # (3, 128, T)\n","            channels = 3\n","\n","        # Crop hoặc pad để đạt đúng fixed_length (333 frames)\n","        if num_frames >= self.fixed_length:\n","            if self.training:\n","                start = random.randint(0, num_frames - self.fixed_length)\n","            else:\n","                start = (num_frames - self.fixed_length) // 2\n","            feature = feature[:, :, start:start + self.fixed_length]\n","        else:\n","            pad_width = self.fixed_length - num_frames\n","            feature = np.pad(feature, ((0, 0), (0, 0), (0, pad_width)), mode='wrap')\n","\n","        # Bây giờ feature chắc chắn là (channels, 128, 333)\n","        feature_tensor = torch.from_numpy(feature).float()\n","\n","        # Quan trọng: reshape để phù hợp với model VGG_11 gốc\n","        if channels > 1:  # delta=True → ghép 3 channel thành 384 mel bins\n","            feature_tensor = feature_tensor.view(channels * mel_bins, self.fixed_length)  # (384, 333)\n","        else:\n","            feature_tensor = feature_tensor.squeeze(0)  # (128, 333)\n","\n","        label = torch.tensor(self.key_to_label.get(key, 0), dtype=torch.long)\n","        return feature_tensor, label\n","\n","    def close(self):\n","        if hasattr(self, 'features_h5'):\n","            self.features_h5.close()"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":56,"status":"ok","timestamp":1768186993239,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"y_LClACDJrZE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"85c8f773-fedd-40b6-d78f-7844d08f8f57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples: 3240\n","Train samples: 2592, Val samples: 648\n"]}],"source":["# ================== CHIA TRAIN/VAL KEYS ==================\n","# Load toàn bộ keys từ file .h5\n","with h5py.File(features_file, 'r') as hf:\n","    all_keys = list(hf.keys())\n","\n","# Load labels để stratify (giữ tỷ lệ lớp khi chia train/val)\n","labels_all = pd.read_csv(label_file).iloc[:, 1].values  # cột label (thường là cột thứ 2)\n","\n","# Chia 80/20, giữ nguyên tỷ lệ nhãn (rất quan trọng cho dataset imbalance như PhysioNet)\n","train_keys, val_keys = train_test_split(\n","    all_keys,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=labels_all\n",")\n","\n","print(f\"Total samples: {len(all_keys)}\")\n","print(f\"Train samples: {len(train_keys)}, Val samples: {len(val_keys)}\")"]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":69,"status":"ok","timestamp":1768186994981,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"},"user_tz":-420},"id":"Iu1TTo5xA3EN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"564f6496-4423-460a-ee27-55d23ec3e85e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train samples: 2592, Val samples: 648\n","Mỗi sample có shape cố định → không cần padding trong collate\n"]}],"source":["train_dataset = LogMelDataset(\n","    features_file,\n","    label_file,\n","    keys=train_keys,\n","    delta=True,      # phải bật vì model train với delta\n","    norm=True,\n","    duration=5,\n","    hop_length=15,\n","    training=True\n",")\n","\n","val_dataset = LogMelDataset(\n","    features_file,\n","    label_file,\n","    keys=val_keys,\n","    delta=True,\n","    norm=True,\n","    duration=5,\n","    hop_length=15,\n","    training=False\n",")\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=32,\n","    shuffle=True,\n","    num_workers=2,        # giảm xuống 2 để tránh warning\n","    pin_memory=True\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=2,\n","    pin_memory=True\n",")\n","\n","print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n","print(\"Mỗi sample có shape cố định → không cần padding trong collate\")"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"ZKkKmnOR5Pwt","executionInfo":{"status":"ok","timestamp":1768186997116,"user_tz":-420,"elapsed":47,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/","height":157},"outputId":"01acd411-7984-469d-a946-05a45fb26dfa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nmodel.train()\\noptimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\\ncriterion = torch.nn.NLLLoss()  # vì model output log_softmax\\n\\nnum_finetune_epochs = 10\\n\\nfor epoch in range(num_finetune_epochs):\\n    model.train()\\n    running_loss = 0.0\\n\\n    for inputs, labels in train_loader:\\n        inputs, labels = inputs.to(device), labels.to(device)\\n\\n        optimizer.zero_grad()\\n        outputs = model(inputs)\\n        loss = criterion(outputs, labels)\\n        loss.backward()\\n        optimizer.step()\\n\\n        running_loss += loss.item()\\n\\n    avg_loss = running_loss / len(train_loader)\\n    print(f\"Fine-tune Epoch {epoch+1}/{num_finetune_epochs} - Avg Loss: {avg_loss:.6f}\")\\n\\n    # Đánh giá trên validation (tùy chọn)\\n    if (epoch + 1) % 5 == 0 or epoch == num_finetune_epochs - 1:\\n        model.eval()\\n        correct = 0\\n        total = 0\\n        with torch.no_grad():\\n            for inputs, labels in val_loader:\\n                inputs, labels = inputs.to(device), labels.to(device)\\n                outputs = model(inputs)\\n                pred = torch.argmax(outputs, dim=1)\\n                correct += (pred == labels).sum().item()\\n                total += labels.size(0)\\n        acc = correct / total if total > 0 else 0\\n        print(f\"   >>> Val Accuracy sau epoch {epoch+1}: {acc:.4f}\")\\n        model.train()\\n\\n# Đóng dataset để giải phóng file handle\\ntrain_dataset.close()\\nval_dataset.close()\\n\\nmodel.eval()\\nprint(\"Fine-tune sau pruning hoàn tất\")\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":68}],"source":["'''\n","model.train()\n","optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n","criterion = torch.nn.NLLLoss()  # vì model output log_softmax\n","\n","num_finetune_epochs = 10\n","\n","for epoch in range(num_finetune_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    avg_loss = running_loss / len(train_loader)\n","    print(f\"Fine-tune Epoch {epoch+1}/{num_finetune_epochs} - Avg Loss: {avg_loss:.6f}\")\n","\n","    # Đánh giá trên validation (tùy chọn)\n","    if (epoch + 1) % 5 == 0 or epoch == num_finetune_epochs - 1:\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                outputs = model(inputs)\n","                pred = torch.argmax(outputs, dim=1)\n","                correct += (pred == labels).sum().item()\n","                total += labels.size(0)\n","        acc = correct / total if total > 0 else 0\n","        print(f\"   >>> Val Accuracy sau epoch {epoch+1}: {acc:.4f}\")\n","        model.train()\n","\n","# Đóng dataset để giải phóng file handle\n","train_dataset.close()\n","val_dataset.close()\n","\n","model.eval()\n","print(\"Fine-tune sau pruning hoàn tất\")\n","'''"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"2BcQ8SgFbH4w","executionInfo":{"status":"ok","timestamp":1768187000062,"user_tz":-420,"elapsed":129,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f89d6a40-0a7b-4b1a-f138-e0d682e01652"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Đã remove pruning mask → pruning permanent\n","✅ Model pruned + finetuned lưu tại: /content/drive/MyDrive/AutomaticHeartSoundClassification-main/TFLITE/crnn_0108_105831_pruned_finetuned.pth\n"]}],"source":["# ================== LÀM PRUNING PERMANENT ==================\n","import torch.nn.utils.prune as prune  # nếu chưa import\n","\n","for module, name in parameters_to_prune:\n","    prune.remove(module, name)\n","\n","print(\"✅ Đã remove pruning mask → pruning permanent\")\n","\n","# ================== LƯU MODEL PRUNED ==================\n","PRUNED_PATH = PROJECT_PATH / \"TFLITE\" / f\"{MODEL_NAME.lower()}_{TIMESTAMP}_pruned_finetuned.pth\"\n","torch.save(model.state_dict(), PRUNED_PATH)\n","print(f\"✅ Model pruned + finetuned lưu tại: {PRUNED_PATH}\")\n","\n","# Đóng h5 file\n","train_dataset.close()"]},{"cell_type":"markdown","metadata":{"id":"x_h2-HDx3dYB"},"source":["## Define input shape & Dummy input"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"pNaWD8uh3cZT","executionInfo":{"status":"ok","timestamp":1768187002304,"user_tz":-420,"elapsed":7,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["# ================== DEFINE INPUT SHAPE & DUMMY INPUT ==================\n","# Input shape cố định sau khi fix dataset: (batch, 384, 333)\n","dummy_input = torch.randn(1, 384, 333).to(device)"]},{"cell_type":"markdown","metadata":{"id":"Ghh46LBo3uGo"},"source":["# Chuyển sang ONXX"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"lBQl35W33wfU","executionInfo":{"status":"ok","timestamp":1768187004089,"user_tz":-420,"elapsed":63,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"29913b38-175f-4ac9-c9fa-aa2eb707a1df"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AutomaticHeartSoundClassification-main/TFLITE/crnn_0108_105831_final.onnx\n"]}],"source":["# Export\n","ONNX_PATH = PROJECT_PATH / \"TFLITE\" / f\"{MODEL_NAME.lower()}_{TIMESTAMP}_final.onnx\"\n","ONNX_PATH.parent.mkdir(parents=True, exist_ok=True)\n","print(ONNX_PATH)"]},{"cell_type":"code","source":["print(\"🔧 Flattening LSTM parameters...\")\n","\n","if hasattr(model, 'bilstm') and hasattr(model.bilstm, 'LSTM'):\n","    model.bilstm.LSTM.flatten_parameters()\n","    print(\"✅ LSTM flattened\\n\")\n","else:\n","    print(\"⚠️  No LSTM found\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uS4F3N8_JIbO","executionInfo":{"status":"ok","timestamp":1768187535932,"user_tz":-420,"elapsed":80,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"217c6579-765e-4a6b-fae8-166c6017de58"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["🔧 Flattening LSTM parameters...\n","✅ LSTM flattened\n","\n"]}]},{"cell_type":"code","execution_count":79,"metadata":{"id":"YJDxNj3GOO5e","executionInfo":{"status":"ok","timestamp":1768187539638,"user_tz":-420,"elapsed":80,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["original_forward = model.forward\n","\n","def export_forward_simple_cnn(input):\n","    B, mel_bins, num_frames = input.size()\n","\n","    x = input.view(B, model.in_channel, -1, num_frames)\n","\n","    x = F.relu(model.bn1(model.conv1(x)))\n","    x = F.max_pool2d(x, 2)\n","\n","    x = F.relu(model.bn2(model.conv2(x)))\n","    x = F.max_pool2d(x, 2)\n","\n","    x = F.relu(model.bn3(model.conv3(x)))\n","    x = F.max_pool2d(x, 2)\n","\n","    x = model.pool(x)\n","    x = x.view(B, -1)\n","\n","    x = F.relu(model.fc1(x))\n","    output = model.output(x)   # Softmax có thể bỏ ở edge\n","    return output\n","\n","def export_forward_vgg(input):\n","    B, mel_bins, num_frames = input.size()\n","    x = input.view(B, model.in_channel, -1, num_frames)\n","    x = x.transpose(1, 2)\n","    x = model.bn0(x)\n","    x = x.transpose(1, 2)\n","\n","    x = model.conv1(x, pool_size=(2, 2), pool_type='max')\n","\n","    x = nn.AdaptiveMaxPool2d((1, 1))(x)\n","    x = x.view(B, -1)\n","    output = model.fc_final(x)\n","    return output\n","\n","def export_forward_crnn(input):\n","    \"\"\"\n","    ONNX-compatible forward pass\n","    Uses fixed kernel size for pooling instead of adaptive pooling\n","    \"\"\"\n","    B, mel_bins, num_frames = input.size()\n","\n","    # Reshape\n","    x = input.view(B, model.in_channel, mel_bins // model.in_channel, num_frames)\n","\n","    # CNN encoder - this includes 4 ConvBlocks with pooling\n","    x = model.cnn(x)\n","\n","    # Pool frequency dimension using FIXED kernel size\n","    # This replaces F.adaptive_max_pool2d(x, (1, None))\n","    x = torch.nn.functional.max_pool2d(\n","        x,\n","        kernel_size=(freq_dim_after_cnn, 1)  # Use calculated size\n","    )\n","    x = x.squeeze(2)  # Remove frequency dimension\n","\n","    # BiLSTM\n","    output = model.bilstm(x)\n","\n","    return output\n","\n","\n","\n","if MODEL_NAME == \"CNN\":\n","    model.forward = export_forward_simple_cnn\n","elif MODEL_NAME == \"VGG11\":\n","    model.forward = export_forward_vgg\n","elif MODEL_NAME == \"CRNN\":\n","    model.forward = export_forward_crnn\n","else:\n","    raise ValueError(\"Unsupported model\")"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Z320InRV3yFr","executionInfo":{"status":"ok","timestamp":1768183835771,"user_tz":-420,"elapsed":1204,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4a7359e-6d23-4616-8ab4-b7214e04cb7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Export ONNX thành công: /content/drive/MyDrive/AutomaticHeartSoundClassification-main/TFLITE/crnn_0108_105831_final.onnx\n","Đã khôi phục forward gốc\n","Size: 14.52 MB\n"]}],"source":["'''\n","try:\n","    torch.onnx.export(\n","        model,\n","        dummy_input,\n","        str(ONNX_PATH),\n","        export_params=True,\n","        opset_version=17,\n","        do_constant_folding=True,\n","        input_names=[\"input\"],\n","        output_names=[\"output\"],\n","        dynamic_axes={\n","            \"input\": {0: \"batch_size\"},\n","            \"output\": {0: \"batch_size\"}\n","        },\n","        dynamo=False\n","        # verbose=False\n","    )\n","    print(f\"✅ Export ONNX thành công: {ONNX_PATH}\")\n","except Exception as e:\n","    print(\"Lỗi export:\", e)\n","finally:\n","    model.forward = original_forward\n","    print(\"Đã khôi phục forward gốc\")\n","\n","# Kiểm tra file\n","import os\n","if os.path.exists(ONNX_PATH):\n","    print(f\"Size: {os.path.getsize(ONNX_PATH) / (1024**2):.2f} MB\")\n","'''"]},{"cell_type":"code","source":["try:\n","    print(f\"📦 Exporting to: {ONNX_PATH.name}\\n\")\n","\n","    torch.onnx.export(\n","        model,\n","        dummy_input,\n","        str(ONNX_PATH),\n","\n","        export_params=True,\n","        opset_version=17,\n","        do_constant_folding=True,\n","\n","        input_names=[\"input\"],\n","        output_names=[\"output\"],\n","\n","        dynamic_axes={\n","            \"input\": {0: \"batch_size\"},\n","            \"output\": {0: \"batch_size\"}\n","        },\n","\n","        dynamo=False,\n","        training=torch.onnx.TrainingMode.EVAL,\n","        keep_initializers_as_inputs=False,\n","        verbose=False\n","    )\n","\n","    print(f\"✅ ONNX export successful!\\n\")\n","\n","except Exception as e:\n","    print(f\"❌ Export failed: {e}\\n\")\n","    import traceback\n","    traceback.print_exc()\n","    raise\n","\n","finally:\n","    model.forward = original_forward\n","    print(\"✅ Restored original forward\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8hInr574Gvpg","executionInfo":{"status":"ok","timestamp":1768187563191,"user_tz":-420,"elapsed":1646,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"03fc25d4-61f2-47b1-b7b8-feeb1290866f"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["📦 Exporting to: crnn_0108_105831_final.onnx\n","\n","✅ ONNX export successful!\n","\n","✅ Restored original forward\n","\n"]}]},{"cell_type":"code","source":["import os\n","if os.path.exists(ONNX_PATH):\n","    file_size_mb = os.path.getsize(ONNX_PATH) / (1024**2)\n","    print(f\"File size: {file_size_mb:.2f} MB\")\n","\n","    # Load and verify with ONNX\n","    import onnx\n","    try:\n","        onnx_model = onnx.load(str(ONNX_PATH))\n","        onnx.checker.check_model(onnx_model)\n","        print(\"ONNX model is valid\")\n","\n","        # Check LSTM nodes\n","        lstm_nodes = [n for n in onnx_model.graph.node if n.op_type == \"LSTM\"]\n","        print(f\"\\nFound {len(lstm_nodes)} LSTM node(s)\")\n","\n","        for i, lstm_node in enumerate(lstm_nodes):\n","            print(f\"\\nLSTM #{i+1}: {lstm_node.name}\")\n","            print(f\"  Number of inputs: {len(lstm_node.input)}\")\n","            for j, inp in enumerate(lstm_node.input):\n","                if inp:  # Only print non-empty inputs\n","                    print(f\"    [{j}] {inp}\")\n","\n","        # Verify with ONNX Runtime\n","        try:\n","            import onnxruntime as ort\n","            sess = ort.InferenceSession(str(ONNX_PATH), providers=['CPUExecutionProvider'])\n","\n","            # Test inference\n","            test_input = dummy_input.cpu().numpy()\n","            ort_output = sess.run(None, {'input': test_input})[0]\n","\n","            # Compare with PyTorch\n","            with torch.no_grad():\n","                torch_output = model(dummy_input).cpu().numpy()\n","\n","            max_diff = abs(torch_output - ort_output).max()\n","            print(f\"\\n🔍 Output comparison:\")\n","            print(f\"  PyTorch output shape: {torch_output.shape}\")\n","            print(f\"  ONNX output shape: {ort_output.shape}\")\n","            print(f\"  Max difference: {max_diff:.6f}\")\n","\n","            if max_diff < 1e-4:\n","                print(\"Outputs match! ONNX export is correct.\")\n","            else:\n","                print(f\" Outputs differ by {max_diff}\")\n","\n","        except ImportError:\n","            print(\"\\nonnxruntime not installed, skipping runtime verification\")\n","        except Exception as e:\n","            print(f\"\\n ONNX Runtime verification failed: {e}\")\n","\n","    except Exception as e:\n","        print(f\"ONNX verification failed: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","else:\n","    print(\"ONNX file not found!\")\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"ONNX EXPORT COMPLETED\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0sJyCzKMIBHD","executionInfo":{"status":"ok","timestamp":1768187568582,"user_tz":-420,"elapsed":556,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"cd2cd16c-c17a-4234-d833-0739b1d22929"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["File size: 14.52 MB\n","ONNX model is valid\n","\n","Found 2 LSTM node(s)\n","\n","LSTM #1: /bilstm/LSTM/LSTM\n","  Number of inputs: 7\n","    [0] /bilstm/LSTM/Transpose_output_0\n","    [1] onnx::LSTM_487\n","    [2] onnx::LSTM_488\n","    [3] onnx::LSTM_486\n","    [5] /bilstm/LSTM/Slice_output_0\n","    [6] /bilstm/LSTM/Slice_1_output_0\n","\n","LSTM #2: /bilstm/LSTM/LSTM_1\n","  Number of inputs: 7\n","    [0] /bilstm/LSTM/Reshape_output_0\n","    [1] onnx::LSTM_530\n","    [2] onnx::LSTM_531\n","    [3] onnx::LSTM_529\n","    [5] /bilstm/LSTM/Slice_2_output_0\n","    [6] /bilstm/LSTM/Slice_3_output_0\n","\n","🔍 Output comparison:\n","  PyTorch output shape: (1, 2)\n","  ONNX output shape: (1, 2)\n","  Max difference: 0.000000\n","Outputs match! ONNX export is correct.\n","\n","============================================================\n","ONNX EXPORT COMPLETED\n"]}]},{"cell_type":"code","execution_count":82,"metadata":{"id":"DJAq-j-P34jS","executionInfo":{"status":"ok","timestamp":1768187577420,"user_tz":-420,"elapsed":43,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd9f586f-5682-4c36-d0d1-454e7c280d60"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Đã chuẩn bị representative dataset từ logmel_features.h5\n"]}],"source":["DATASET_PATH = Path('/content/drive/MyDrive/AutomaticHeartSoundClassification-main/data')\n","sys.path.append(str(DATASET_PATH))\n","\n","features_file = DATASET_PATH / \"logmel_features.h5\"\n","label_file = DATASET_PATH / \"label.csv\"\n","\n","# Load labels để biết số sample\n","labels = pd.read_csv(label_file)\n","num_samples = len(labels)\n","\n","# Load một phần features làm representative dataset (100-300 samples là đủ)\n","def representative_data_gen():\n","    with h5py.File(features_file, 'r') as hf:\n","        for i in range(300):  # Dùng 300 samples để calibrate\n","            idx = i % num_samples\n","            key = list(hf.keys())[idx]  # Hoặc hf['features'][idx] nếu là array\n","            data = hf[key][()]\n","            data = np.expand_dims(data, axis=0)  # Add batch dim\n","            data = data.astype(np.float32)\n","            yield [data]\n","\n","print(\"✅ Đã chuẩn bị representative dataset từ logmel_features.h5\")"]},{"cell_type":"markdown","metadata":{"id":"RBzITLuS4hge"},"source":["# CONVERT ONNX -> TFLITE"]},{"cell_type":"markdown","metadata":{"id":"vYVAFhAeqKkj"},"source":["## ONXX"]},{"cell_type":"code","source":["import onnx\n","m = onnx.load(ONNX_PATH)\n","print(\"IR version:\", m.ir_version)"],"metadata":{"id":"scgecVR6lYRq","executionInfo":{"status":"ok","timestamp":1768187579448,"user_tz":-420,"elapsed":196,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c05ed5b6-0ce7-406b-d4a0-75650c51d77b"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["IR version: 8\n"]}]},{"cell_type":"code","source":["import onnx\n","\n","from onnxsim import simplify\n","\n","model = onnx.load(ONNX_PATH)\n","model_simp, check = simplify(model)\n","\n","onnx.save(model_simp, f\"{MODEL_NAME.lower()}_{TIMESTAMP}_final.onnx\")"],"metadata":{"id":"2XX8tEGayAKb","executionInfo":{"status":"ok","timestamp":1768187581390,"user_tz":-420,"elapsed":1011,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"execution_count":84,"outputs":[]},{"cell_type":"code","source":["import onnxruntime as ort\n","try:\n","    # Thử nạp model bằng ONNX Runtime\n","    session = ort.InferenceSession(str(ONNX_PATH))\n","    print(\"✅ Model ONNX hợp lệ và sẵn sàng chuyển đổi TFLite.\")\n","except Exception as e:\n","    print(f\"❌ Model vẫn lỗi cấu trúc: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vIwOqzRzM6J","executionInfo":{"status":"ok","timestamp":1768187583051,"user_tz":-420,"elapsed":74,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"c00736af-8830-4ee4-b13a-0f15f7fa6cef"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model ONNX hợp lệ và sẵn sàng chuyển đổi TFLite.\n"]}]},{"cell_type":"code","execution_count":86,"metadata":{"id":"S8qBq3iFGobl","executionInfo":{"status":"ok","timestamp":1768187594056,"user_tz":-420,"elapsed":9264,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b4d7b35-8bfa-4ce2-84fc-ecebf3be975e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples: 3240\n","Prepared 50/300 calibration samples\n","Prepared 100/300 calibration samples\n","Prepared 150/300 calibration samples\n","Prepared 200/300 calibration samples\n","Prepared 250/300 calibration samples\n","Prepared 300/300 calibration samples\n","✅ Đã lưu file calib_data.npy (shape: (300, 384, 333) )\n"]}],"source":["import h5py\n","import numpy as np\n","import librosa\n","from pathlib import Path\n","\n","PROJECT_PATH = Path('/content/drive/MyDrive/AutomaticHeartSoundClassification-main')\n","DATASET_PATH = PROJECT_PATH / \"data\"\n","features_file = DATASET_PATH / \"logmel_features.h5\"\n","\n","DURATION = 5\n","HOP_LENGTH_MS = 15\n","FIXED_LENGTH = int(DURATION * 1000 / HOP_LENGTH_MS)  # 333\n","DELTA = True\n","NORM = True\n","\n","def standard_normal_variate(data):\n","    mean = np.mean(data)\n","    std = np.std(data) + 1e-8\n","    return (data - mean) / std\n","\n","calib_data_list = []\n","\n","with h5py.File(features_file, 'r') as hf:\n","    all_keys = list(hf.keys())\n","    num_samples = len(all_keys)\n","    print(f\"Total samples: {num_samples}\")\n","\n","    for i in range(300):\n","        key = all_keys[i % num_samples]\n","        feature = hf[key][()]\n","\n","        if NORM:\n","            feature = standard_normal_variate(feature)\n","\n","        if feature.ndim == 2:\n","            feature = feature[np.newaxis, :, :]\n","\n","        if DELTA:\n","            orig = feature[0]\n","            delta1 = librosa.feature.delta(orig)\n","            delta2 = librosa.feature.delta(delta1)\n","            feature = np.stack([orig, delta1, delta2], axis=0)\n","\n","        channels, mel_bins, num_frames = feature.shape\n","\n","        if num_frames >= FIXED_LENGTH:\n","            start = num_frames // 2 - FIXED_LENGTH // 2\n","            feature = feature[:, :, start:start + FIXED_LENGTH]\n","        else:\n","            pad_width = FIXED_LENGTH - num_frames\n","            feature = np.pad(feature, ((0,0), (0,0), (0, pad_width)), mode='wrap')\n","\n","        if channels > 1:\n","            feature = feature.reshape(channels * mel_bins, FIXED_LENGTH)  # (384, 333)\n","\n","        feature = feature.astype(np.float32)\n","        feature = np.expand_dims(feature, axis=0)  # (1, 384, 333)\n","        calib_data_list.append(feature)\n","\n","        if (i + 1) % 50 == 0:\n","            print(f\"Prepared {i + 1}/300 calibration samples\")\n","\n","# Ghép thành array (300, 1, 384, 333) rồi lưu .npy\n","calibration_data = np.concatenate(calib_data_list, axis=0)\n","np.save(\"calib_data.npy\", calibration_data)\n","print(\"✅ Đã lưu file calib_data.npy (shape:\", calibration_data.shape, \")\")"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"wUDzVfrlMZ2A","executionInfo":{"status":"ok","timestamp":1768183843480,"user_tz":-420,"elapsed":78,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eba317ea-5a6a-43a7-bc68-3db8f4bceb9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Đang dùng ONNX: crnn_0108_105831_final.onnx\n","Tên input OP trong ONNX: 'input'\n"]}],"source":["import onnx\n","from pathlib import Path\n","\n","PROJECT_PATH = Path('/content/drive/MyDrive/AutomaticHeartSoundClassification-main')\n","TFLITE_DIR = PROJECT_PATH / \"TFLITE\"\n","\n","model_prefix = f\"{MODEL_NAME.lower()}_{TIMESTAMP}\"\n","\n","onnx_files = (\n","    list(TFLITE_DIR.glob(f\"{model_prefix}_final.onnx\")) +\n","    list(TFLITE_DIR.glob(f\"{model_prefix}.onnx\"))\n",")\n","\n","if not onnx_files:\n","    raise FileNotFoundError(f\"Không tìm thấy ONNX cho {model_prefix}\")\n","\n","# Lấy file mới nhất (phòng trường hợp export nhiều lần)\n","onnx_path = max(onnx_files, key=lambda p: p.stat().st_mtime)\n","\n","print(f\"Đang dùng ONNX: {onnx_path.name}\")\n","\n","model = onnx.load(str(onnx_path))\n","input_name = model.graph.input[0].name\n","print(f\"Tên input OP trong ONNX: '{input_name}'\")"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"8ehQzp5tL7yO","executionInfo":{"status":"ok","timestamp":1768187608313,"user_tz":-420,"elapsed":61,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"563269e8-de5e-4167-9ccf-031646531545"},"outputs":[{"output_type":"stream","name":"stdout","text":["Đang dùng ONNX: crnn_0108_105831_final.onnx\n"]}],"source":["from pathlib import Path\n","import onnx2tf\n","\n","# =========================\n","# 1. PATH CONFIGURATION\n","# =========================\n","\n","OUTPUT_TFLITE_DIR = TFLITE_DIR / f\"{MODEL_NAME.lower()}_tflite_int8_{TIMESTAMP}\"\n","output_folder_path=str(OUTPUT_TFLITE_DIR),\n","\n","onnx_files = (\n","    list(TFLITE_DIR.glob(f\"{MODEL_NAME.lower()}_{TIMESTAMP}_final.onnx\")) +\n","    list(TFLITE_DIR.glob(f\"{MODEL_NAME.lower()}_{TIMESTAMP}.onnx\"))\n",")\n","\n","if not onnx_files:\n","    raise FileNotFoundError(f\"Không tìm thấy file ONNX trong {TFLITE_DIR}\")\n","\n","onnx_path = sorted(\n","    onnx_files,\n","    key=lambda p: p.stat().st_mtime,\n","    reverse=True\n",")[0]\n","\n","print(f\"Đang dùng ONNX: {onnx_path.name}\")"]},{"cell_type":"code","source":["json_path = OUTPUT_TFLITE_DIR / f\"{onnx_path.stem}_auto.json\"\n","\n","print(f\"Kiểm tra file cấu hình: {json_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvmttqfK_Q9b","executionInfo":{"status":"ok","timestamp":1768187612173,"user_tz":-420,"elapsed":42,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"f3881704-65de-444f-f21b-a902065f694f"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Kiểm tra file cấu hình: /content/drive/MyDrive/AutomaticHeartSoundClassification-main/TFLITE/crnn_tflite_int8_0108_105831/crnn_0108_105831_final_auto.json\n"]}]},{"cell_type":"code","source":["\n","# 2. ONNX → TFLITE INT8\n","# CNN and VGG\n","'''\n","onnx2tf.convert(\n","    input_onnx_file_path=str(onnx_path),\n","    output_folder_path=(OUTPUT_TFLITE_DIR),\n","\n","    param_replacement_file=str(json_path) if json_path.exists() else None,\n","\n","    # --- TFLite settings ---\n","    copy_onnx_input_output_names_to_tflite=True,\n","    output_integer_quantized_tflite=True,\n","    quant_type=\"per-tensor\",   # có thể đổi sang \"per-channel\"\n","\n","    # --- FIX SHAPE (RẤT QUAN TRỌNG) ---\n","    batch_size=1,\n","    overwrite_input_shape=[\n","        \"input:1,384,333\"   # (B, C*Mel, Time)\n","    ],\n","\n","    # --- INT8 CALIBRATION DATA ---\n","    custom_input_op_name_np_data_path=[\n","        [\n","            \"input\",            # tên input trong ONNX\n","            \"calib_data.npy\",   # (300, 384, 333)\n","            0.0,                # mean\n","            1.0                 # std\n","        ]\n","    ],\n","\n","    non_verbose=False\n",")\n","\n","print(\"Chuyển đổi thành công sang TFLite INT8!\")\n","print(\"Output nằm trong thư mục: vgg11_tflite_int8_final/\")\n","print(\n","    f\"Output nằm trong thư mục: \"\n","    f\"{MODEL_NAME.lower()}_tflite_int8_{TIMESTAMP}/\"\n",")\n","'''"],"metadata":{"id":"p0YTVgJfDzfa","executionInfo":{"status":"ok","timestamp":1768183843586,"user_tz":-420,"elapsed":51,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"colab":{"base_uri":"https://localhost:8080/","height":157},"outputId":"354f5676-75a9-4164-cb36-0f721a366b11"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nonnx2tf.convert(\\n    input_onnx_file_path=str(onnx_path),\\n    output_folder_path=(OUTPUT_TFLITE_DIR),\\n\\n    param_replacement_file=str(json_path) if json_path.exists() else None,\\n\\n    # --- TFLite settings ---\\n    copy_onnx_input_output_names_to_tflite=True,\\n    output_integer_quantized_tflite=True,\\n    quant_type=\"per-tensor\",   # có thể đổi sang \"per-channel\"\\n\\n    # --- FIX SHAPE (RẤT QUAN TRỌNG) ---\\n    batch_size=1,\\n    overwrite_input_shape=[\\n        \"input:1,384,333\"   # (B, C*Mel, Time)\\n    ],\\n\\n    # --- INT8 CALIBRATION DATA ---\\n    custom_input_op_name_np_data_path=[\\n        [\\n            \"input\",            # tên input trong ONNX\\n            \"calib_data.npy\",   # (300, 384, 333)\\n            0.0,                # mean\\n            1.0                 # std\\n        ]\\n    ],\\n\\n    non_verbose=False\\n)\\n\\nprint(\"Chuyển đổi thành công sang TFLite INT8!\")\\nprint(\"Output nằm trong thư mục: vgg11_tflite_int8_final/\")\\nprint(\\n    f\"Output nằm trong thư mục: \"\\n    f\"{MODEL_NAME.lower()}_tflite_int8_{TIMESTAMP}/\"\\n)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["import onnx\n","from pathlib import Path\n","\n","# ============================================================\n","# LOAD ONNX MODEL\n","# ============================================================\n","ONNX_PATH = PROJECT_PATH / \"TFLITE\" / f\"{MODEL_NAME.lower()}_{TIMESTAMP}_final.onnx\"\n","MODIFIED_ONNX_PATH = PROJECT_PATH / \"TFLITE\" / f\"{MODEL_NAME.lower()}_{TIMESTAMP}_no_init_state.onnx\"\n","\n","print(\"=\"*60)\n","print(\"REMOVING LSTM INITIAL STATES FROM ONNX\")\n","print(\"=\"*60)\n","print(f\"\\nLoading: {ONNX_PATH.name}\")\n","\n","model = onnx.load(str(ONNX_PATH))\n","\n","# ============================================================\n","# FIND AND MODIFY LSTM NODES\n","# ============================================================\n","lstm_nodes_found = 0\n","lstm_nodes_modified = 0\n","\n","for node in model.graph.node:\n","    if node.op_type == \"LSTM\":\n","        lstm_nodes_found += 1\n","\n","        print(f\"\\n📍 Found LSTM: {node.name}\")\n","        print(f\"   Inputs before: {len(node.input)}\")\n","\n","        # Show all inputs\n","        for i, inp in enumerate(node.input):\n","            if inp:\n","                print(f\"     [{i}] {inp}\")\n","            else:\n","                print(f\"     [{i}] (empty)\")\n","\n","        # LSTM standard inputs are:\n","        # [0] X - input tensor\n","        # [1] W - weight tensor\n","        # [2] R - recurrence weight tensor\n","        # [3] B - bias tensor\n","        # [4] sequence_lens - (optional, can be empty)\n","        # [5] initial_h - (REMOVE THIS)\n","        # [6] initial_c - (REMOVE THIS)\n","\n","        # Keep only first 5 inputs (X, W, R, B, sequence_lens)\n","        original_inputs = list(node.input)\n","\n","        # If there are more than 5 inputs, remove the extra ones\n","        if len(original_inputs) > 5:\n","            # Keep inputs 0-4, remove 5 and 6 (initial states)\n","            node.input[:] = original_inputs[:5]\n","            lstm_nodes_modified += 1\n","\n","            print(f\"   ✅ Modified to {len(node.input)} inputs\")\n","            print(f\"   Removed inputs: {original_inputs[5:]}\")\n","        else:\n","            print(f\"   ℹ️  Already has {len(node.input)} inputs (no modification needed)\")\n","\n","print(f\"\\n📊 Summary:\")\n","print(f\"   LSTM nodes found: {lstm_nodes_found}\")\n","print(f\"   LSTM nodes modified: {lstm_nodes_modified}\")\n","\n","# ============================================================\n","# SAVE MODIFIED ONNX\n","# ============================================================\n","print(f\"\\n💾 Saving modified model to: {MODIFIED_ONNX_PATH.name}\")\n","\n","onnx.save(model, str(MODIFIED_ONNX_PATH))\n","\n","# Verify the saved model\n","try:\n","    onnx.checker.check_model(model)\n","    print(\"✅ Modified ONNX model is valid\\n\")\n","except Exception as e:\n","    print(f\"❌ Model validation failed: {e}\\n\")\n","\n","# ============================================================\n","# VERIFY MODIFICATIONS\n","# ============================================================\n","print(\"=\"*60)\n","print(\"VERIFICATION\")\n","print(\"=\"*60)\n","\n","# Reload and check\n","model_verify = onnx.load(str(MODIFIED_ONNX_PATH))\n","\n","for node in model_verify.graph.node:\n","    if node.op_type == \"LSTM\":\n","        num_inputs = len([inp for inp in node.input if inp])\n","        print(f\"\\nLSTM: {node.name}\")\n","        print(f\"  Total inputs: {num_inputs}\")\n","\n","        for i, inp in enumerate(node.input):\n","            if inp:\n","                print(f\"    [{i}] {inp}\")\n","\n","        if num_inputs <= 5:\n","            print(f\"  ✅ SUCCESS! No initial states\")\n","        else:\n","            print(f\"  ⚠️  Still has {num_inputs} inputs\")\n","\n","# ============================================================\n","# TEST WITH ONNX RUNTIME\n","# ============================================================\n","try:\n","    import onnxruntime as ort\n","\n","    print(\"\\n🧪 Testing with ONNX Runtime...\")\n","\n","    sess = ort.InferenceSession(\n","        str(MODIFIED_ONNX_PATH),\n","        providers=['CPUExecutionProvider']\n","    )\n","\n","    # Test inference\n","    import numpy as np\n","    test_input = np.random.randn(1, 384, 333).astype(np.float32)\n","    output = sess.run(None, {'input': test_input})[0]\n","\n","    print(f\"✅ ONNX Runtime test successful\")\n","    print(f\"   Input shape: {test_input.shape}\")\n","    print(f\"   Output shape: {output.shape}\")\n","\n","except ImportError:\n","    print(\"\\n⚠️  onnxruntime not installed, skipping runtime test\")\n","except Exception as e:\n","    print(f\"\\n❌ ONNX Runtime test failed: {e}\")\n","    import traceback\n","    traceback.print_exc()\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"✅ ONNX MODIFICATION COMPLETE\")\n","print(\"=\"*60)\n","print(f\"\\nUse this file for TFLite conversion:\")\n","print(f\"  {MODIFIED_ONNX_PATH.name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_9GYlAWtB_lY","executionInfo":{"status":"ok","timestamp":1768187794883,"user_tz":-420,"elapsed":345,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"9e71a759-2aaf-4885-e303-66144f528965"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","REMOVING LSTM INITIAL STATES FROM ONNX\n","============================================================\n","\n","Loading: crnn_0108_105831_final.onnx\n","\n","📍 Found LSTM: /bilstm/LSTM/LSTM\n","   Inputs before: 7\n","     [0] /bilstm/LSTM/Transpose_output_0\n","     [1] onnx::LSTM_487\n","     [2] onnx::LSTM_488\n","     [3] onnx::LSTM_486\n","     [4] (empty)\n","     [5] /bilstm/LSTM/Slice_output_0\n","     [6] /bilstm/LSTM/Slice_output_0\n","   ✅ Modified to 5 inputs\n","   Removed inputs: ['/bilstm/LSTM/Slice_output_0', '/bilstm/LSTM/Slice_output_0']\n","\n","📍 Found LSTM: /bilstm/LSTM/LSTM_1\n","   Inputs before: 7\n","     [0] /bilstm/LSTM/Reshape_output_0\n","     [1] onnx::LSTM_530\n","     [2] onnx::LSTM_531\n","     [3] onnx::LSTM_529\n","     [4] (empty)\n","     [5] /bilstm/LSTM/Slice_output_0\n","     [6] /bilstm/LSTM/Slice_output_0\n","   ✅ Modified to 5 inputs\n","   Removed inputs: ['/bilstm/LSTM/Slice_output_0', '/bilstm/LSTM/Slice_output_0']\n","\n","📊 Summary:\n","   LSTM nodes found: 2\n","   LSTM nodes modified: 2\n","\n","💾 Saving modified model to: crnn_0108_105831_no_init_state.onnx\n","✅ Modified ONNX model is valid\n","\n","============================================================\n","VERIFICATION\n","============================================================\n","\n","LSTM: /bilstm/LSTM/LSTM\n","  Total inputs: 4\n","    [0] /bilstm/LSTM/Transpose_output_0\n","    [1] onnx::LSTM_487\n","    [2] onnx::LSTM_488\n","    [3] onnx::LSTM_486\n","  ✅ SUCCESS! No initial states\n","\n","LSTM: /bilstm/LSTM/LSTM_1\n","  Total inputs: 4\n","    [0] /bilstm/LSTM/Reshape_output_0\n","    [1] onnx::LSTM_530\n","    [2] onnx::LSTM_531\n","    [3] onnx::LSTM_529\n","  ✅ SUCCESS! No initial states\n","\n","🧪 Testing with ONNX Runtime...\n","✅ ONNX Runtime test successful\n","   Input shape: (1, 384, 333)\n","   Output shape: (1, 2)\n","\n","============================================================\n","✅ ONNX MODIFICATION COMPLETE\n","============================================================\n","\n","Use this file for TFLite conversion:\n","  crnn_0108_105831_no_init_state.onnx\n"]}]},{"cell_type":"code","source":["import onnx\n","from pathlib import Path\n","\n","ONNX_PATH = PROJECT_PATH / \"TFLITE\" / f\"{MODEL_NAME.lower()}_{TIMESTAMP}_final.onnx\"\n","MODIFIED_ONNX_PATH = PROJECT_PATH / \"TFLITE\" / f\"{MODEL_NAME.lower()}_{TIMESTAMP}_no_init_state.onnx\"\n","\n","print(\"Đang xóa initial states từ LSTM...\\n\")\n","\n","model = onnx.load(str(ONNX_PATH))\n","\n","for node in model.graph.node:\n","    if node.op_type == \"LSTM\":\n","        print(f\"LSTM: {node.name}\")\n","        print(f\"  Inputs trước: {len(node.input)}\")\n","\n","        original_inputs = list(node.input)\n","        if len(original_inputs) > 5:\n","            node.input[:] = original_inputs[:5]\n","            print(f\"  Inputs sau: {len(node.input)}\")\n","            print(f\"  ✅ Đã xóa: {original_inputs[5:]}\\n\")\n","\n","onnx.save(model, str(MODIFIED_ONNX_PATH))\n","print(f\"✅ Lưu: {MODIFIED_ONNX_PATH.name}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MqJ6LFpiOQAV","executionInfo":{"status":"ok","timestamp":1768188087202,"user_tz":-420,"elapsed":311,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"e09221e7-19b2-4513-ad3a-2285d9af74ba"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["Đang xóa initial states từ LSTM...\n","\n","LSTM: /bilstm/LSTM/LSTM\n","  Inputs trước: 7\n","  Inputs sau: 5\n","  ✅ Đã xóa: ['/bilstm/LSTM/Slice_output_0', '/bilstm/LSTM/Slice_output_0']\n","\n","LSTM: /bilstm/LSTM/LSTM_1\n","  Inputs trước: 7\n","  Inputs sau: 5\n","  ✅ Đã xóa: ['/bilstm/LSTM/Slice_output_0', '/bilstm/LSTM/Slice_output_0']\n","\n","✅ Lưu: crnn_0108_105831_no_init_state.onnx\n"]}]},{"cell_type":"code","source":["onnx2tf.convert(\n","    input_onnx_file_path=str(MODIFIED_ONNX_PATH),\n","    output_folder_path=(OUTPUT_TFLITE_DIR),\n","\n","    param_replacement_file=str(json_path) if json_path.exists() else None,\n","\n","    # --- TFLite settings ---\n","    copy_onnx_input_output_names_to_tflite=True,\n","    output_integer_quantized_tflite=True,\n","    quant_type=\"per-tensor\",   # có thể đổi sang \"per-channel\"\n","\n","    # --- FIX SHAPE (RẤT QUAN TRỌNG) ---\n","    batch_size=1,\n","    overwrite_input_shape=[\n","        \"input:1,384,333\"   # (B, C*Mel, Time)\n","    ],\n","\n","    # --- INT8 CALIBRATION DATA ---\n","    custom_input_op_name_np_data_path=[\n","        [\n","            \"input\",            # tên input trong ONNX\n","            \"calib_data.npy\",   # (300, 384, 333)\n","            0.0,                # mean\n","            1.0                 # std\n","        ]\n","    ],\n","\n","    non_verbose=False\n",")\n","\n","print(\"Chuyển đổi thành công sang TFLite INT8!\")\n","print(\"Output nằm trong thư mục: vgg11_tflite_int8_final/\")\n","print(\n","    f\"Output nằm trong thư mục: \"\n","    f\"{MODEL_NAME.lower()}_tflite_int8_{TIMESTAMP}/\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NV1Fvc85OuYQ","executionInfo":{"status":"error","timestamp":1768188252596,"user_tz":-420,"elapsed":5982,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}},"outputId":"150df30a-8b38-4da0-f927-7afdcf114009"},"execution_count":101,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\u001b[07mModel optimizing started\u001b[0m ============================================================\n","Simplifying...\n","Finish! Here is the difference:\n","┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n","┃            ┃ Original Model ┃ Simplified Model ┃\n","┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n","│ Constant   │ 27             │ 27               │\n","│ Conv       │ 8              │ 8                │\n","│ Gather     │ 1              │ 1                │\n","│ LSTM       │ 2              │ 2                │\n","│ MatMul     │ 1              │ 1                │\n","│ MaxPool    │ 5              │ 5                │\n","│ Relu       │ 8              │ 8                │\n","│ Reshape    │ 3              │ 3                │\n","│ Squeeze    │ 1              │ 1                │\n","│ Transpose  │ 4              │ 4                │\n","│ Model Size │ 14.5MiB        │ 14.5MiB          │\n","└────────────┴────────────────┴──────────────────┘\n","\n","Simplifying...\n","Finish! Here is the difference:\n","┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n","┃            ┃ Original Model ┃ Simplified Model ┃\n","┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n","│ Constant   │ 27             │ 27               │\n","│ Conv       │ 8              │ 8                │\n","│ Gather     │ 1              │ 1                │\n","│ LSTM       │ 2              │ 2                │\n","│ MatMul     │ 1              │ 1                │\n","│ MaxPool    │ 5              │ 5                │\n","│ Relu       │ 8              │ 8                │\n","│ Reshape    │ 3              │ 3                │\n","│ Squeeze    │ 1              │ 1                │\n","│ Transpose  │ 4              │ 4                │\n","│ Model Size │ 14.5MiB        │ 14.5MiB          │\n","└────────────┴────────────────┴──────────────────┘\n","\n","Simplifying...\n","Finish! Here is the difference:\n","┏━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n","┃            ┃ Original Model ┃ Simplified Model ┃\n","┡━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n","│ Constant   │ 27             │ 27               │\n","│ Conv       │ 8              │ 8                │\n","│ Gather     │ 1              │ 1                │\n","│ LSTM       │ 2              │ 2                │\n","│ MatMul     │ 1              │ 1                │\n","│ MaxPool    │ 5              │ 5                │\n","│ Relu       │ 8              │ 8                │\n","│ Reshape    │ 3              │ 3                │\n","│ Squeeze    │ 1              │ 1                │\n","│ Transpose  │ 4              │ 4                │\n","│ Model Size │ 14.5MiB        │ 14.5MiB          │\n","└────────────┴────────────────┴──────────────────┘\n","\n","\u001b[32mModel optimizing complete!\u001b[0m\n","\n","\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n","\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n","\n","\u001b[07mModel loaded\u001b[0m ========================================================================\n","\n","\u001b[07mModel conversion started\u001b[0m ============================================================\n","\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input \u001b[32mshape\u001b[0m: [1, 384, 333] \u001b[32mdtype\u001b[0m: float32\n","\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n","\u001b[33mWARNING:\u001b[0m [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Got invalid dimensions for input: input for the following indices\n"," index: 1 Got: 333 Expected: 384\n"," index: 2 Got: 384 Expected: 333\n"," Please fix either the inputs/outputs or the model.\n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m2 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Reshape\u001b[35m onnx_op_name\u001b[0m: /Reshape\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input \u001b[36mshape\u001b[0m: [1, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Concat_output_0 \u001b[36mshape\u001b[0m: [4] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /Reshape_output_0 \u001b[36mshape\u001b[0m: [1, 1, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.tensor\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_171/transpose:0 \u001b[34mshape\u001b[0m: (1, 384, 333) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.shape\u001b[0m: \u001b[34mval\u001b[0m: [1, 1, 384, 333] \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.reshape_32/Reshape:0 \u001b[34mshape\u001b[0m: (1, 1, 384, 333) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m3 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv1/conv1/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /Reshape_output_0 \u001b[36mshape\u001b[0m: [1, 1, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_420 \u001b[36mshape\u001b[0m: [32, 1, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_421 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_172/transpose:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 1) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 1, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_208/Add:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m4 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv1/Relu\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv1/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_208/Add:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_208/Relu:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m5 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv1/conv2/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_423 \u001b[36mshape\u001b[0m: [32, 32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_424 \u001b[36mshape\u001b[0m: [32] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_208/Relu:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (32,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_209/Add:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m6 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv1/Relu_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv1/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv1/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_209/Add:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_209/Relu:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m7 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /cnn/conv1/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv1/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 32, 384, 333] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 32, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_209/Relu:0 \u001b[34mshape\u001b[0m: (1, 384, 333, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_120/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m8 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv2/conv1/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv1/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 32, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_426 \u001b[36mshape\u001b[0m: [64, 32, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_427 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_120/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 32) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 32, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_210/Add:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m9 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv2/Relu\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv2/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_210/Add:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_210/Relu:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m10 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv2/conv2/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv2/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_429 \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_430 \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_210/Relu:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_211/Add:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m11 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv2/Relu_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv2/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv2/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_211/Add:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_211/Relu:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m12 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /cnn/conv2/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv2/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 64, 192, 166] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_211/Relu:0 \u001b[34mshape\u001b[0m: (1, 192, 166, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_121/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m13 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv3/conv1/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv2/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_432 \u001b[36mshape\u001b[0m: [128, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_433 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv3/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_121/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_212/Add:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m14 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv3/Relu\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv3/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_212/Add:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_212/Relu:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m15 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv3/conv2/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_435 \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_436 \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv3/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_212/Relu:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_213/Add:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m16 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv3/Relu_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv3/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv3/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_213/Add:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_213/Relu:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m17 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /cnn/conv3/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv3/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 128, 96, 83] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv3/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 128, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_213/Relu:0 \u001b[34mshape\u001b[0m: (1, 96, 83, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_122/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m18 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv4/conv1/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv3/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 128, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_438 \u001b[36mshape\u001b[0m: [256, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_439 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv4/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_122/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_214/Add:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m19 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv4/Relu\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv4/conv1/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv4/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_214/Add:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_214/Relu:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m20 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /cnn/conv4/conv2/Conv\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv4/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::Conv_441 \u001b[36mshape\u001b[0m: [256, 256, 3, 3] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::Conv_442 \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv4/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_214/Relu:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 256, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_215/Add:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m21 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /cnn/conv4/Relu_1\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv4/conv2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv4/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_215/Add:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_215/Relu:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m22 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /cnn/conv4/MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv4/Relu_1_output_0 \u001b[36mshape\u001b[0m: [1, 256, 48, 41] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /cnn/conv4/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 24, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_215/Relu:0 \u001b[34mshape\u001b[0m: (1, 48, 41, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_123/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 24, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m23 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /MaxPool\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /cnn/conv4/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 24, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_123/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 24, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [24, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [24, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_124/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 1, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m24 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Squeeze\u001b[35m onnx_op_name\u001b[0m: sng_Squeeze_0\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 256, 1, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: /Constant_6_output_0 \u001b[36mshape\u001b[0m: [1] \u001b[36mdtype\u001b[0m: int64\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: 81 \u001b[36mshape\u001b[0m: [1, 256, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: squeeze_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_124/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 1, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.axis\u001b[0m: \u001b[34mval\u001b[0m: [1] \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_89/sng_Squeeze_0:0 \u001b[34mshape\u001b[0m: (1, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m25 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Transpose\u001b[35m onnx_op_name\u001b[0m: /bilstm/LSTM/Transpose\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: 81 \u001b[36mshape\u001b[0m: [1, 256, 20] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /bilstm/LSTM/Transpose_output_0 \u001b[36mshape\u001b[0m: [20, 1, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: transpose_v2\n","\u001b[32mINFO:\u001b[0m \u001b[34m input.1.a\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.squeeze_89/sng_Squeeze_0:0 \u001b[34mshape\u001b[0m: (1, 20, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\u001b[32mINFO:\u001b[0m \u001b[34m input.2.perm\u001b[0m: \u001b[34mval\u001b[0m: [1, 0, 2] \n","\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.compat.v1.transpose_173/transpose:0 \u001b[34mshape\u001b[0m: (20, 1, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n","\n","\u001b[32mINFO:\u001b[0m \u001b[32m26 / 34\u001b[0m\n","\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: LSTM\u001b[35m onnx_op_name\u001b[0m: /bilstm/LSTM/LSTM\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /bilstm/LSTM/Transpose_output_0 \u001b[36mshape\u001b[0m: [20, 1, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: onnx::LSTM_487 \u001b[36mshape\u001b[0m: [2, 1024, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: onnx::LSTM_488 \u001b[36mshape\u001b[0m: [2, 1024, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.4\u001b[0m: onnx::LSTM_486 \u001b[36mshape\u001b[0m: [2, 2048] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m input_name.5\u001b[0m:  \u001b[36mshape\u001b[0m: None \u001b[36mdtype\u001b[0m: None\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /bilstm/LSTM/LSTM_output_0 \u001b[36mshape\u001b[0m: [20, 2, 1, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.2\u001b[0m: /bilstm/LSTM/LSTM_output_1 \u001b[36mshape\u001b[0m: [2, 1, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[32mINFO:\u001b[0m \u001b[36m output_name.3\u001b[0m: /bilstm/LSTM/LSTM_output_2 \u001b[36mshape\u001b[0m: [2, 1, 256] \u001b[36mdtype\u001b[0m: float32\n","\u001b[31mERROR:\u001b[0m The trace log is below.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/onnx2tf/utils/common_functions.py\", line 314, in print_wrapper_func\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/onnx2tf/utils/common_functions.py\", line 388, in inverted_operation_enable_disable_wrapper_func\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/onnx2tf/utils/common_functions.py\", line 57, in get_replacement_parameter_wrapper_func\n","    func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.12/dist-packages/onnx2tf/ops/LSTM.py\", line 801, in make_node\n","    backward_initial_state = [] + [tf.convert_to_tensor(initial_h[1])]\n","                                                        ~~~~~~~~~^^^\n","TypeError: 'NoneType' object is not subscriptable\n","\n","\u001b[31mERROR:\u001b[0m input_onnx_file_path: /content/drive/MyDrive/AutomaticHeartSoundClassification-main/TFLITE/crnn_0108_105831_no_init_state.onnx\n","\u001b[31mERROR:\u001b[0m onnx_op_name: wa/bilstm/LSTM/LSTM\n","\u001b[31mERROR:\u001b[0m Read this and deal with it. https://github.com/PINTO0309/onnx2tf#parameter-replacement\n","\u001b[31mERROR:\u001b[0m Alternatively, if the input OP has a dynamic dimension, use the -b or -ois option to rewrite it to a static shape and try again.\n","\u001b[31mERROR:\u001b[0m If the input OP of ONNX before conversion is NHWC or an irregular channel arrangement other than NCHW, use the -kt or -kat option.\n","\u001b[31mERROR:\u001b[0m Also, for models that include NonMaxSuppression in the post-processing, try the -onwdt option.\n"]},{"output_type":"error","ename":"TypeError","evalue":"'NoneType' object is not subscriptable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-442176687.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m onnx2tf.convert(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_onnx_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODIFIED_ONNX_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_folder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_TFLITE_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparam_replacement_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjson_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2tf/onnx2tf.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_norm_mean, quant_norm_std, quant_type, custom_input_op_name_np_data_path, input_quant_dtype, output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, shape_hints, no_large_tensor, output_nms_with_dynamic_tensor, switch_nms_version, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, auto_generate_json, auto_generate_json_...\n\u001b[1;32m   1302\u001b[0m                     )\n\u001b[1;32m   1303\u001b[0m             \u001b[0;31m# Re-raise the original error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0madditional_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'onnx_tensor_infos_for_validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2tf/onnx2tf.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(input_onnx_file_path, onnx_graph, output_folder_path, output_signaturedefs, output_h5, output_keras_v3, output_tfv1_pb, output_weights, copy_onnx_input_output_names_to_tflite, output_dynamic_range_quantized_tflite, output_integer_quantized_tflite, quant_norm_mean, quant_norm_std, quant_type, custom_input_op_name_np_data_path, input_quant_dtype, output_quant_dtype, not_use_onnxsim, not_use_opname_auto_generate, batch_size, overwrite_input_shape, shape_hints, no_large_tensor, output_nms_with_dynamic_tensor, switch_nms_version, keep_ncw_or_nchw_or_ncdhw_input_names, keep_nwc_or_nhwc_or_ndhwc_input_names, keep_shape_absolutely_input_names, input_names_to_interrupt_model_conversion, output_names_to_interrupt_model_conversion, disable_group_convolution, enable_accumulation_type_float16, enable_batchmatmul_unfold, enable_rnn_unroll, disable_suppression_flextranspose, disable_strict_mode, number_of_dimensions_after_flextranspose_compression, disable_suppression_flexstridedslice, number_of_dimensions_after_flexstridedslice_compression, optimization_for_gpu_delegate, replace_argmax_to_reducemax_and_indices_is_int64, replace_argmax_to_reducemax_and_indices_is_float32, replace_argmax_to_fused_argmax_and_indices_is_int64, replace_argmax_to_fused_argmax_and_indices_is_float32, fused_argmax_scale_ratio, replace_to_pseudo_operators, param_replacement_file, auto_generate_json, auto_generate_json_...\n\u001b[1;32m   1216\u001b[0m                 \u001b[0msanitizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m                 op.make_node(\n\u001b[0m\u001b[1;32m   1219\u001b[0m                     \u001b[0mgraph_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                     \u001b[0mtf_layers_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_layers_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36mprint_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m                     )\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mget_log_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mLOG_LEVELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'debug'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36minverted_operation_enable_disable_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverted_operation_enable_disable_wrapper_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \"\"\"\n\u001b[1;32m    390\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0moutput_shape_trans\u001b[0m \u001b[0mstores\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdetermining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2tf/utils/common_functions.py\u001b[0m in \u001b[0;36mget_replacement_parameter_wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mreplacement_parameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'op_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             ]\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_replacement_parameter_wrapper_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2tf/ops/LSTM.py\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(graph_node, tf_layers_dict, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minitial_h\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minitial_c\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mforward_initial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_initial_state\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0mbackward_initial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_h\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_c\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mbackward_initial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_initial_state\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"]}]},{"cell_type":"markdown","metadata":{"id":"-O9W8NeterYU"},"source":["# Test Model"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"7sh6BQNlbk70","executionInfo":{"status":"ok","timestamp":1768188267850,"user_tz":-420,"elapsed":8,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["OUTPUT_TFLITE_DIR = TFLITE_DIR / f\"{MODEL_NAME.lower()}_tflite_int8_{TIMESTAMP}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6xWjESBU-3R","executionInfo":{"status":"aborted","timestamp":1768183848727,"user_tz":-420,"elapsed":27519,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["from pathlib import Path\n","\n","output_dir = Path(OUTPUT_TFLITE_DIR)\n","print(\"Các file/thư mục trong output:\")\n","for item in output_dir.iterdir():\n","    print(item.name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQMdVxV9CvJF","executionInfo":{"status":"aborted","timestamp":1768183848729,"user_tz":-420,"elapsed":27518,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["import tensorflow as tf\n","from pathlib import Path\n","\n","\n","print(f\"Đang kiểm tra thư mục: {OUTPUT_TFLITE_DIR}\\n\")\n","\n","# Kiểm tra xem thư mục có tồn tại không\n","if not OUTPUT_TFLITE_DIR.exists():\n","    raise FileNotFoundError(f\"Thư mục không tồn tại: {OUTPUT_TFLITE_DIR}\\n\"\n","                            \"Hãy kiểm tra lại tên thư mục hoặc chạy lại phần chuyển đổi ONNX → TFLite.\")\n","\n","# Liệt kê tất cả file .tflite trong thư mục\n","tflite_files = list(OUTPUT_TFLITE_DIR.glob(\"*.tflite\"))\n","\n","if not tflite_files:\n","    raise FileNotFoundError(f\"Không tìm thấy file .tflite nào trong {OUTPUT_TFLITE_DIR}\")\n","\n","# In danh sách file kèm kích thước\n","print(\"=== DANH SÁCH FILE TFLITE & KÍCH THƯỚC ===\")\n","def format_size(size_bytes):\n","    for unit in ['B', 'KB', 'MB', 'GB']:\n","        if size_bytes < 1024:\n","            return f\"{size_bytes:.2f} {unit}\"\n","        size_bytes /= 1024\n","    return f\"{size_bytes:.2f} TB\"\n","\n","for file_path in sorted(tflite_files):\n","    size = file_path.stat().st_size\n","    print(f\"{file_path.name:<55} {format_size(size)}\")\n","\n","print()  # dòng trống\n","\n","# Chọn file INT8 ưu tiên (có chứa \"integer\", \"int8\", \"quant\")\n","int8_file = next(\n","    (f for f in tflite_files if any(keyword in f.name.lower() for keyword in [\"integer\", \"int8\", \"quant\"])),\n","    tflite_files[0]  # nếu không có thì dùng file đầu tiên\n",")\n","\n","print(f\"Đang test với: {int8_file.name} ({format_size(int8_file.stat().st_size)})\\n\")\n","\n","# Load và test model\n","interpreter = tf.lite.Interpreter(model_path=str(int8_file))\n","interpreter.allocate_tensors()\n","\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","print(\"=== THÔNG TIN INPUT ===\")\n","for i, detail in enumerate(input_details):\n","    print(f\"Input {i}:\")\n","    print(f\"  Name: {detail['name']}\")\n","    print(f\"  Shape: {detail['shape']}\")\n","    print(f\"  Dtype: {detail['dtype']}\")\n","    print(f\"  Quantization: {detail['quantization']}\")\n","\n","print(\"\\n=== THÔNG TIN OUTPUT ===\")\n","for detail in output_details:\n","    print(f\"Output shape: {detail['shape']}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKIlMv8Vetjy","executionInfo":{"status":"aborted","timestamp":1768183848737,"user_tz":-420,"elapsed":27522,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["import h5py\n","import pandas as pd\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import librosa\n","from pathlib import Path\n","\n","PROJECT_PATH = Path('/content/drive/MyDrive/AutomaticHeartSoundClassification-main')\n","DATASET_PATH = PROJECT_PATH / \"data\"\n","\n","features_file = DATASET_PATH / \"logmel_features.h5\"\n","label_file = DATASET_PATH / \"label.csv\"\n","\n","# ================== LOGMEL DATASET ==================\n","EPS = 1e-8\n","\n","def standard_normal_variate(data):\n","    mean = np.mean(data)\n","    std = np.std(data) + EPS\n","    return (data - mean) / std\n","\n","class LogMelDataset(Dataset):\n","    def __init__(self, features_h5_path, label_csv_path, keys=None,\n","                 delta=True, norm=True, duration=5, hop_length=15, training=False):\n","        self.features_h5 = h5py.File(features_h5_path, 'r')\n","        self.labels_df = pd.read_csv(label_csv_path)\n","\n","        if keys is None:\n","            self.keys = list(self.features_h5.keys())\n","        else:\n","            self.keys = keys\n","\n","        # Map filename (stem) → label\n","        self.key_to_label = dict(zip(self.labels_df.iloc[:, 0].astype(str), self.labels_df.iloc[:, 1]))\n","\n","        self.delta = delta\n","        self.norm = norm\n","        self.duration = duration\n","        self.hop_length = hop_length\n","        self.training = training\n","        self.fixed_length = int(self.duration * 1000 / self.hop_length)  # 333 frames\n","\n","    def __len__(self):\n","        return len(self.keys)\n","\n","    def __getitem__(self, idx):\n","        key = self.keys[idx]\n","        feature = self.features_h5[key][()]  # (mel_bins, time_frames)\n","\n","        if self.norm:\n","            feature = standard_normal_variate(feature)\n","\n","        if feature.ndim == 2:\n","            feature = feature[np.newaxis, :, :]  # (1, mel, T)\n","\n","        channels, mel_bins, num_frames = feature.shape\n","\n","        if self.delta:\n","            orig = feature[0]\n","            delta1 = librosa.feature.delta(orig)\n","            delta2 = librosa.feature.delta(delta1)\n","            feature = np.stack([orig, delta1, delta2], axis=0)  # (3, mel, T)\n","            channels = 3\n","\n","        # Crop/pad to fixed 333 frames\n","        if num_frames >= self.fixed_length:\n","            start = (num_frames - self.fixed_length) // 2\n","            feature = feature[:, :, start:start + self.fixed_length]\n","        else:\n","            pad_width = self.fixed_length - num_frames\n","            feature = np.pad(feature, ((0,0),(0,0),(0,pad_width)), mode='wrap')\n","\n","        # Ghép 3 channel → 384 mel bins (như trong model VGG11)\n","        if channels > 1:\n","            feature = feature.reshape(channels * mel_bins, self.fixed_length)  # (384, 333)\n","\n","        feature_tensor = torch.from_numpy(feature).float()  # (384, 333)\n","\n","        label = torch.tensor(self.key_to_label.get(key, 0), dtype=torch.long)\n","        return feature_tensor, label\n","\n","    def close(self):\n","        self.features_h5.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fgWDsV3devhM","executionInfo":{"status":"aborted","timestamp":1768183848740,"user_tz":-420,"elapsed":27521,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["# Load toàn bộ keys\n","with h5py.File(features_file, 'r') as hf:\n","    all_keys = list(hf.keys())\n","\n","print(f\"Tổng số mẫu: {len(all_keys)}\")\n","\n","# Tạo dataset toàn bộ (dùng để test cuối cùng)\n","full_dataset = LogMelDataset(\n","    features_file,\n","    label_file,\n","    keys=all_keys,\n","    delta=True,\n","    norm=True,\n","    duration=5,\n","    hop_length=15,\n","    training=False  # không random crop\n",")\n","\n","full_loader = DataLoader(\n","    full_dataset,\n","    batch_size=32,\n","    shuffle=False,\n","    num_workers=2,\n","    pin_memory=True\n",")\n","\n","print(\"✅ Đã tạo DataLoader thành công!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DewFVNZVex07","executionInfo":{"status":"aborted","timestamp":1768183848743,"user_tz":-420,"elapsed":27520,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","\n","def test_tflite_accuracy(tflite_path, data_loader):\n","    # Load TFLite model\n","    interpreter = tf.lite.Interpreter(model_path=str(tflite_path))\n","    interpreter.allocate_tensors()\n","\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    input_shape = input_details[0]['shape']  # ví dụ [1, 333, 384] hoặc [1, 384, 333]\n","\n","    print(f\"Testing model: {tflite_path.name}\")\n","    print(f\"Expected input shape: {input_shape}\")\n","\n","    correct = 0\n","    total = 0\n","\n","    for features, labels in data_loader:\n","        batch_size = features.shape[0]\n","\n","        for i in range(batch_size):\n","            x = features[i].numpy()  # (384, 333)\n","\n","            # Điều chỉnh shape theo model TFLite yêu cầu\n","            if input_shape[1] == 333 and input_shape[2] == 384:\n","                x = x.transpose(1, 0)  # (333, 384)\n","            # Nếu là (1, 384, 333) → giữ nguyên\n","\n","            x = np.expand_dims(x, axis=0).astype(np.float32)  # (1, H, W)\n","\n","            interpreter.set_tensor(input_details[0]['index'], x)\n","            interpreter.invoke()\n","            output = interpreter.get_tensor(output_details[0]['index'])  # (1, 2)\n","\n","            pred = np.argmax(output, axis=1)[0]\n","            true_label = labels[i].item()\n","\n","            if pred == true_label:\n","                correct += 1\n","            total += 1\n","\n","    accuracy = correct / total\n","    print(f\"=> Accuracy trên {total} mẫu: {accuracy*100:.2f}% ({correct}/{total})\")\n","    print(\"-\" * 60)\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9smgNBV3ezLq","executionInfo":{"status":"aborted","timestamp":1768183848820,"user_tz":-420,"elapsed":27593,"user":{"displayName":"Ahn Đức","userId":"03706930103223800336"}}},"outputs":[],"source":["from pathlib import Path\n","\n","# Tìm file INT8\n","tflite_files = list(OUTPUT_TFLITE_DIR.glob(\"*integer*.tflite\")) + list(OUTPUT_TFLITE_DIR.glob(\"*quant*.tflite\"))\n","if not tflite_files:\n","    raise FileNotFoundError(\"Không tìm thấy file TFLite INT8!\")\n","\n","int8_tflite_path = tflite_files[0]\n","print(f\"Đang test với: {int8_tflite_path.name}\")\n","\n","# Chạy test\n","test_tflite_accuracy(int8_tflite_path, full_loader)\n","\n","# Đóng dataset\n","full_dataset.close()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPQ0fEfG+k9ScrTGF4DPAvn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}